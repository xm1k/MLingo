[
  {
    "question": "Что такое машинное обучение?",
    "options": [
      "Алгоритмы, которые учатся на данных",
      "Программирование роботов",
      "Метод работы с большими данными",
      "Система для распознавания текста"
    ],
    "explanation": "Машинное обучение позволяет моделям учиться на данных."
  },
  {
    "question": "Что такое глубокое обучение?",
    "options": [
      "Алгоритмы с несколькими слоями нейронных сетей",
      "Метод для уменьшения объема данных",
      "Алгоритм для работы с изображениями",
      "Модели, использующие небольшие нейросети"
    ],
    "explanation": "Глубокое обучение использует многослойные нейронные сети."
  },
  {
    "question": "Что такое метод опорных векторов (SVM)?",
    "options": [
      "Метод классификации и регрессии",
      "Метод для работы с текстовыми данными",
      "Метод для кластеризации данных",
      "Алгоритм для обработки временных рядов"
    ],
    "explanation": "SVM используется для классификации и регрессии."
  },
  {
    "question": "Что такое переобучение модели?",
    "options": [
      "Модель слишком хорошо запоминает обучающие данные",
      "Модель не может обучаться на данных",
      "Модель плохо предсказывает новые данные",
      "Модель делает верные прогнозы на всех данных"
    ],
    "explanation": "Переобучение происходит, когда модель слишком точно запоминает данные."
  },
  {
    "question": "Что такое регуляризация в машинном обучении?",
    "options": [
      "Метод предотвращения переобучения",
      "Метод для улучшения скорости обучения",
      "Метод кластеризации данных",
      "Метод для нормализации данных"
    ],
    "explanation": "Регуляризация добавляет штраф за сложные модели, предотвращая переобучение."
  },
  {
    "question": "Как работает алгоритм K-средних?",
    "options": [
      "Метод кластеризации, основанный на расстояниях до центроидов",
      "Метод для классификации категорий",
      "Алгоритм для прогнозирования будущих значений",
      "Метод для обработки изображений"
    ],
    "explanation": "K-средних группирует данные в кластеры по минимальному расстоянию."
  },
  {
    "question": "Что такое кросс-валидация?",
    "options": [
      "Метод для оценки качества модели",
      "Метод для ускорения обучения модели",
      "Метод для преобразования данных",
      "Метод для работы с несбалансированными данными"
    ],
    "explanation": "Кросс-валидация оценивает модель, разделяя данные на части."
  },
  {
    "question": "Что такое градиентный спуск?",
    "options": [
      "Алгоритм оптимизации для минимизации ошибок",
      "Метод для кластеризации данных",
      "Алгоритм для классификации",
      "Метод для нормализации данных"
    ],
    "explanation": "Градиентный спуск минимизирует функцию потерь при обучении модели."
  },
  {
    "question": "Что такое ансамблирование в машинном обучении?",
    "options": [
      "Метод объединения нескольких моделей для улучшения прогноза",
      "Метод кластеризации с несколькими центроидами",
      "Алгоритм для создания нейронных сетей",
      "Метод для повышения скорости обучения"
    ],
    "explanation": "Ансамблирование объединяет несколько моделей для улучшения точности."
  },
  {
    "question": "Что такое искусственные нейронные сети?",
    "options": [
      "Модели, имитирующие работу человеческого мозга",
      "Алгоритмы для обработки текстовых данных",
      "Метод для классификации данных",
      "Алгоритмы для создания случайных чисел"
    ],
    "explanation": "Нейронные сети — это алгоритмы, имитирующие работу мозга для решения задач."
  },
  {
    "question": "Что такое логистическая регрессия?",
    "options": [
      "Алгоритм для классификации данных",
      "Алгоритм для прогноза числовых значений",
      "Метод для кластеризации данных",
      "Метод для работы с изображениями"
    ],
    "explanation": "Логистическая регрессия применяется для классификации, особенно бинарной."
  },
  {
    "question": "Что такое поддержка обучения с подкреплением?",
    "options": [
      "Обучение через награды и наказания",
      "Обучение с использованием меток для каждого примера",
      "Метод для решения задач с данными, разделенными на классы",
      "Метод для кластеризации по признакам"
    ],
    "explanation": "Обучение с подкреплением основано на получении наград за действия."
  },
  {
    "question": "Что такое автокодировщик?",
    "options": [
      "Модель для уменьшения размерности данных",
      "Метод для регрессии и классификации",
      "Алгоритм для работы с текстами",
      "Метод для обработки изображений"
    ],
    "explanation": "Автокодировщик восстанавливает данные из их сжатых представлений."
  },
  {
    "question": "Что такое метрика F1?",
    "options": [
      "Среднее гармоническое точности и полноты",
      "Метод для оценки значимости признаков",
      "Метрика для оценки скорости обучения",
      "Метод для нормализации ошибок"
    ],
    "explanation": "F1-метрика объединяет точность и полноту для оценки модели."
  },
  {
    "question": "Что такое Precision в классификации?",
    "options": [
      "Доля правильных положительных предсказаний",
      "Доля правильных отрицательных предсказаний",
      "Метрика для работы с большими данными",
      "Доля верных прогнозов всех типов"
    ],
    "explanation": "Precision измеряет, насколько точны положительные предсказания."
  },
  {
    "question": "Что такое Recall в классификации?",
    "options": [
      "Доля правильных положительных из всех реальных положительных",
      "Доля правильных отрицательных из всех реальных отрицательных",
      "Метод для поиска аномалий",
      "Метрика для работы с временными рядами"
    ],
    "explanation": "Recall измеряет, насколько хорошо модель находит все положительные случаи."
  },
  {
    "question": "Какой алгоритм используется для регрессии?",
    "options": [
      "Линейная регрессия",
      "K-средних",
      "Генетический алгоритм",
      "Глубокое обучение"
    ],
    "explanation": "Линейная регрессия применяется для прогнозирования числовых значений."
  },
  {
    "question": "Как работает алгоритм случайного леса?",
    "options": [
      "Использует ансамбль решающих деревьев для классификации",
      "Кластеризует данные с помощью центроидов",
      "Использует один алгоритм для всех типов задач",
      "Создает нейронные сети для каждого признака"
    ],
    "explanation": "Случайный лес использует ансамбль деревьев для классификации или регрессии."
  },
  {
    "question": "Что такое обучение без учителя?",
    "options": [
      "Обучение без использования меток данных",
      "Обучение с метками данных",
      "Обучение через взаимодействие с пользователем",
      "Метод обучения с подкреплением"
    ],
    "explanation": "Обучение без учителя не требует меток для обучения модели."
  },
  {
    "question": "Что такое Overfitting?",
    "options": [
      "Переобучение модели",
      "Недообучение модели",
      "Использование данных без обработки",
      "Оптимизация гиперпараметров"
    ],
    "explanation": "Overfitting — это ситуация, когда модель запоминает данные вместо обучения."
  },
  {
    "question": "Что такое Underfitting?",
    "options": [
      "Недостаточное обучение модели",
      "Переобучение модели",
      "Использование метрик с низкой точностью",
      "Увеличение объема данных"
    ],
    "explanation": "Underfitting происходит, когда модель слишком проста для данных."
  },
  {
    "question": "Что такое Feature Scaling?",
    "options": [
      "Нормализация или стандартизация данных",
      "Удаление незначимых признаков",
      "Создание новых признаков",
      "Применение регуляризации"
    ],
    "explanation": "Feature Scaling приводит признаки к одинаковому масштабу для обучения."
  },
  {
    "question": "Что такое Bagging?",
    "options": [
      "Ансамблирование моделей с бутстрепингом",
      "Метод кластеризации данных",
      "Оптимизация весов модели",
      "Улучшение качества данных"
    ],
    "explanation": "Bagging создает ансамбли моделей, обученных на случайных подвыборках."
  },
  {
    "question": "Что такое Boosting?",
    "options": [
      "Ансамблирование слабых моделей для улучшения прогноза",
      "Метод для кластеризации",
      "Метод уменьшения переобучения",
      "Алгоритм для обработки изображений"
    ],
    "explanation": "Boosting усиливает слабые модели, улучшая итоговый результат."
  },
  {
    "question": "Что такое Cross Entropy Loss?",
    "options": [
      "Функция потерь для задач классификации",
      "Метрика для оценки регрессии",
      "Функция для поиска оптимальных параметров",
      "Метод кластеризации данных"
    ],
    "explanation": "Cross Entropy Loss применяется для классификации, измеряя разницу между распределениями."
  },
  {
    "question": "Что такое PCA (Principal Component Analysis)?",
    "options": [
      "Метод уменьшения размерности данных",
      "Алгоритм для поиска аномалий",
      "Метод для классификации",
      "Алгоритм для регрессии"
    ],
    "explanation": "PCA уменьшает размерность данных, сохраняя наиболее важную информацию."
  },
  {
    "question": "Что такое One-hot encoding?",
    "options": [
      "Преобразование категориальных данных в бинарный формат",
      "Метод нормализации данных",
      "Метод уменьшения размерности",
      "Алгоритм для улучшения классификации"
    ],
    "explanation": "One-hot encoding преобразует категории в бинарный формат для обучения."
  },
  {
    "question": "Что такое ROC-кривая?",
    "options": [
      "График точности против полноты",
      "График скорости обучения",
      "Метод уменьшения ошибок",
      "Метод для оптимизации модели"
    ],
    "explanation": "ROC-кривая показывает соотношение между истинными положительными и ложными положительными."
  },
  {
    "question": "Что такое AUC (Area Under Curve)?",
    "options": [
      "Площадь под ROC-кривой",
      "Метод для классификации",
      "Метод для нормализации",
      "Алгоритм для кластеризации"
    ],
    "explanation": "AUC измеряет качество классификации, интегрируя ROC-кривую."
  },
  {
    "question": "Что такое Random Initialization?",
    "options": [
      "Случайная инициализация весов модели",
      "Выбор случайных данных для обучения",
      "Случайная проверка гиперпараметров",
      "Случайная генерация метрик"
    ],
    "explanation": "Random Initialization помогает избежать застревания в локальных минимумах."
  },
  {
    "question": "Что такое Dropout?",
    "options": [
      "Регуляризация через отключение нейронов",
      "Метод для ускорения обучения",
      "Алгоритм для кластеризации",
      "Функция потерь для задач регрессии"
    ],
    "explanation": "Dropout временно отключает нейроны, чтобы избежать переобучения."
  },
  {
    "question": "Что такое Epoch?",
    "options": [
      "Один полный проход по всем данным",
      "Итерация обучения модели",
      "Часть данных для тестирования",
      "Функция для вычисления ошибки"
    ],
    "explanation": "Epoch — это один полный проход модели по обучающему набору данных."
  },
  {
    "question": "Что такое Minibatch?",
    "options": [
      "Подмножество данных для одной итерации обучения",
      "Метод для уменьшения ошибок",
      "Случайная подвыборка данных",
      "Алгоритм для кластеризации"
    ],
    "explanation": "Minibatch — это небольшой набор данных, используемый для одной итерации обучения."
  },
  {
    "question": "Что такое L1-регуляризация?",
    "options": [
      "Метод штрафования больших значений весов",
      "Метод для ускорения обучения",
      "Метод для кластеризации данных",
      "Метод для улучшения точности"
    ],
    "explanation": "L1-регуляризация добавляет штраф за абсолютные значения весов модели."
  },
  {
    "question": "Что такое L2-регуляризация?",
    "options": [
      "Метод штрафования квадратов весов",
      "Метод для уменьшения размерности",
      "Алгоритм для кластеризации",
      "Метод для улучшения качества данных"
    ],
    "explanation": "L2-регуляризация добавляет штраф за квадраты весов, предотвращая переобучение."
  },
  {
    "question": "Что такое Softmax?",
    "options": [
      "Функция активации для многошаговой классификации",
      "Метод нормализации данных",
      "Функция для уменьшения размерности",
      "Метод кластеризации данных"
    ],
    "explanation": "Softmax преобразует выходы модели в вероятности."
  },
  {
    "question": "Что такое Backpropagation?",
    "options": [
      "Алгоритм для обновления весов модели",
      "Метод для уменьшения ошибки",
      "Метод для работы с большими данными",
      "Алгоритм для кластеризации"
    ],
    "explanation": "Backpropagation оптимизирует веса модели, вычисляя градиенты."
  },
  {
    "question": "Что такое Hyperparameter Tuning?",
    "options": [
      "Оптимизация параметров модели",
      "Обучение с использованием гиперпараметров",
      "Метод для оценки качества модели",
      "Алгоритм для работы с текстами"
    ],
    "explanation": "Hyperparameter Tuning выбирает оптимальные значения гиперпараметров."
  },
  {
    "question": "Что такое Gradient Clipping?",
    "options": [
      "Ограничение величины градиента",
      "Ускорение сходимости модели",
      "Метод для кластеризации данных",
      "Алгоритм для работы с временными рядами"
    ],
    "explanation": "Gradient Clipping предотвращает большие значения градиента, стабилизируя обучение."
  },
  {
    "question": "Что такое Reinforcement Learning?",
    "options": [
      "Обучение с наградами и штрафами",
      "Обучение с учителем",
      "Обучение без учителя",
      "Алгоритм для кластеризации"
    ],
    "explanation": "Reinforcement Learning — это обучение, где агент получает награды или штрафы за действия."
  },
  {
    "question": "Что такое Gradient Descent?",
    "options": [
      "Алгоритм оптимизации для минимизации потерь",
      "Метод уменьшения размерности данных",
      "Метод нормализации данных",
      "Алгоритм для кластеризации"
    ],
    "explanation": "Gradient Descent обновляет параметры модели, минимизируя функцию потерь."
  },
  {
    "question": "Что такое Learning Rate?",
    "options": [
      "Шаг обновления параметров модели",
      "Скорость обработки данных",
      "Объем данных для обучения",
      "Метод регуляризации"
    ],
    "explanation": "Learning Rate — это параметр, определяющий, насколько сильно обновляются веса."
  },
  {
    "question": "Что такое Decision Tree?",
    "options": [
      "Модель на основе правил для классификации и регрессии",
      "Модель для кластеризации",
      "Метод для уменьшения ошибок",
      "Функция активации"
    ],
    "explanation": "Decision Tree разбивает данные на основе правил, создавая древовидную структуру."
  },
  {
    "question": "Что такое Ensemble Learning?",
    "options": [
      "Комбинирование нескольких моделей",
      "Обучение одной модели на разных данных",
      "Метод уменьшения размерности",
      "Регуляризация модели"
    ],
    "explanation": "Ensemble Learning объединяет предсказания нескольких моделей для улучшения результатов."
  },
  {
    "question": "Что такое Transfer Learning?",
    "options": [
      "Использование обученной модели для новой задачи",
      "Создание новых данных для обучения",
      "Перенос данных между моделями",
      "Улучшение качества данных"
    ],
    "explanation": "Transfer Learning использует знания, полученные на одной задаче, для другой задачи."
  },
  {
    "question": "Что такое Logistic Regression?",
    "options": [
      "Модель для бинарной классификации",
      "Модель для регрессии",
      "Метод для кластеризации",
      "Функция для нормализации"
    ],
    "explanation": "Logistic Regression используется для прогнозирования вероятностей в задачах классификации."
  },
  {
    "question": "Что такое Naive Bayes?",
    "options": [
      "Классификатор на основе теоремы Байеса",
      "Метод для кластеризации данных",
      "Модель для регрессии",
      "Функция потерь для задач классификации"
    ],
    "explanation": "Naive Bayes использует теорему Байеса и предполагает независимость признаков."
  },
  {
    "question": "Что такое K-Nearest Neighbors (KNN)?",
    "options": [
      "Алгоритм на основе близости данных",
      "Метод уменьшения размерности",
      "Функция для нормализации",
      "Модель для временных рядов"
    ],
    "explanation": "KNN классифицирует или предсказывает значения на основе ближайших соседей."
  },
  {
    "question": "Что такое Regularization?",
    "options": [
      "Метод для предотвращения переобучения",
      "Оптимизация гиперпараметров",
      "Метод кластеризации",
      "Метод нормализации данных"
    ],
    "explanation": "Regularization добавляет штрафы к функции потерь, чтобы избежать переобучения."
  },
  {
    "question": "Что такое Activation Function?",
    "options": [
      "Функция для преобразования входных данных в нейронах",
      "Метод для уменьшения ошибок",
      "Функция потерь",
      "Метод нормализации данных"
    ],
    "explanation": "Activation Function определяет, активируется ли нейрон на основе входных данных."
  },
  {
    "question": "Что такое Hyperplane?",
    "options": [
      "Граница, разделяющая классы в данных",
      "Метод нормализации данных",
      "Модель для временных рядов",
      "Функция активации"
    ],
    "explanation": "Hyperplane — это плоскость, которая разделяет данные в пространстве признаков."
  },
  {
    "question": "Что такое Feature Engineering?",
    "options": [
      "Создание новых признаков из существующих данных",
      "Метод нормализации данных",
      "Оптимизация модели",
      "Уменьшение размера данных"
    ],
    "explanation": "Feature Engineering включает создание или преобразование признаков для улучшения модели."
  },
  {
    "question": "Что такое Mean Squared Error (MSE)?",
    "options": [
      "Средний квадрат ошибки предсказания",
      "Метод кластеризации",
      "Метод нормализации",
      "Функция активации"
    ],
    "explanation": "MSE измеряет среднюю величину ошибки между предсказанными и истинными значениями."
  },
  {
    "question": "Что такое Gradient Vanishing?",
    "options": [
      "Градиенты становятся слишком малыми для обновления весов",
      "Градиенты растут до бесконечности",
      "Модель теряет данные",
      "Метод для кластеризации"
    ],
    "explanation": "Gradient Vanishing возникает, когда градиенты уменьшаются до нуля, препятствуя обучению."
  },
  {
    "question": "Что такое Early Stopping?",
    "options": [
      "Остановка обучения при отсутствии улучшений",
      "Ускорение обучения модели",
      "Метод для уменьшения размерности",
      "Метод кластеризации"
    ],
    "explanation": "Early Stopping завершает обучение, чтобы избежать переобучения."
  },
  {
    "question": "Что такое Adam Optimizer?",
    "options": [
      "Алгоритм оптимизации с адаптивной скоростью обучения",
      "Метод кластеризации данных",
      "Функция для нормализации",
      "Метод уменьшения ошибок"
    ],
    "explanation": "Adam Optimizer использует адаптивные шаги обновления весов для ускорения сходимости."
  },
  {
    "question": "Что такое Multi-Collinearity?",
    "options": [
      "Высокая корреляция между признаками",
      "Метод нормализации данных",
      "Метод кластеризации",
      "Функция активации"
    ],
    "explanation": "Multi-Collinearity возникает, когда признаки сильно коррелированы, что может повлиять на модель."
  },
  {
    "question": "Что такое Clustering?",
    "options": [
      "Группировка данных по схожести",
      "Метод для уменьшения ошибок",
      "Обучение модели с учителем",
      "Метод нормализации"
    ],
    "explanation": "Clustering — это метод объединения объектов в группы на основе их свойств."
  },
  {
    "question": "Что такое Sampling Bias?",
    "options": [
      "Смещение из-за несбалансированной выборки",
      "Метод нормализации данных",
      "Метод кластеризации",
      "Алгоритм для улучшения модели"
    ],
    "explanation": "Sampling Bias возникает, когда выборка не является репрезентативной для всей популяции."
  },
  {
    "question": "Какую роль играет функция активации в нейронной сети?",
    "options": [
      "Она решает, активировать ли нейрон",
      "Она определяет структуру сети",
      "Она отвечает за обработку данных на входе",
      "Она управляет скоростью обучения"
    ],
    "correct_answer": "Она решает, активировать ли нейрон",
    "explanation": "Функция активации добавляет нелинейность в работу нейронной сети, что позволяет модели решать сложные задачи. Она определяет, какой сигнал передавать дальше по сети, основываясь на входных данных."
  },
  {
    "question": "Какую роль играет функция активации в нейронной сети?",
    "options": [
      "Она решает, активировать ли нейрон",
      "Она определяет структуру сети",
      "Она отвечает за обработку данных на входе",
      "Она управляет скоростью обучения"
    ],
    "explanation": "Функция активации добавляет нелинейность в работу нейронной сети, что позволяет модели решать сложные задачи. Она определяет, какой сигнал передавать дальше по сети, основываясь на входных данных."
  },
  {
    "question": "Какой из методов борьбы с переобучением предполагает искусственное уменьшение сложности модели?",
    "options": [
      "Регуляризация",
      "Аугментация данных",
      "Dropout",
      "Раннее завершение обучения (Early stopping)"
    ],
    "explanation": "Регуляризация добавляет штраф к функции потерь за слишком большие веса модели, что помогает уменьшить сложность модели и предотвратить переобучение."
  },
  {
    "question": "Какая архитектура нейронной сети чаще всего используется для обработки последовательностей?",
    "options": [
      "Рекуррентная нейронная сеть (RNN)",
      "Свёрточная нейронная сеть (CNN)",
      "Перцептрон",
      "Сеть внимания (Transformer)"
    ],
    "explanation": "Рекуррентные нейронные сети (RNN) специально разработаны для обработки последовательных данных, таких как временные ряды или текст, благодаря своей способности учитывать зависимость между временными шагами."
  },
  {
    "question": "Что такое 'переполнение' при обучении модели?",
    "options": [
      "Модель слишком хорошо запоминает данные обучения",
      "Модель показывает низкую точность на данных обучения",
      "Процесс обучения занимает слишком много памяти",
      "Модель не может обновлять веса из-за градиентного затухания"
    ],
    "explanation": "Переполнение (overfitting) происходит, когда модель слишком хорошо адаптируется к обучающим данным, теряя способность обобщать на новых, ранее невидимых данных."
  },
  {
    "question": "Какой метод увеличивает количество обучающих данных, изменяя исходные изображения (например, повороты, зеркалирование)?",
    "options": [
      "Аугментация данных",
      "Dropout",
      "Batch Normalization",
      "Линейная интерполяция"
    ],
    "explanation": "Аугментация данных создаёт новые экземпляры данных путём применения преобразований, таких как вращение, масштабирование или отражение, что помогает улучшить обобщающую способность модели."
  },
  {
    "question": "Для какой задачи лучше всего подходит сеть Transformer?",
    "options": [
      "Обработка текста",
      "Обработка изображений",
      "Анализ временных рядов",
      "Распознавание аномалий"
    ],
    "explanation": "Архитектура Transformer хорошо подходит для обработки текста, поскольку она использует механизм внимания, позволяющий учитывать долгосрочные зависимости между словами в предложении."
  },
  {
    "question": "Какой из следующих терминов описывает ситуацию, когда градиенты становятся слишком малы для обновления весов модели?",
    "options": [
      "Градиентное исчезновение",
      "Градиентный взрыв",
      "Дисбаланс данных",
      "Смещение весов"
    ],
    "explanation": "Градиентное исчезновение возникает, когда значения градиентов становятся настолько малыми, что веса модели почти не обновляются, что особенно часто встречается в глубоких сетях."
  },
  {
    "question": "Что происходит, если в модели используется слишком низкий коэффициент обучения?",
    "options": [
      "Обучение замедляется или прекращается",
      "Модель начинает переобучаться",
      "Модель теряет способность обобщать данные",
      "Происходит градиентный взрыв"
    ],
    "explanation": "При низком коэффициенте обучения шаги обновления весов становятся слишком малыми, что может замедлить или полностью остановить процесс оптимизации."
  },
  {
    "question": "Какой подход позволяет нейронной сети автоматически корректировать внутренние распределения активаций?",
    "options": [
      "Batch Normalization",
      "Dropout",
      "L2-регуляризация",
      "Адаптивный спуск градиента (Adam)"
    ],
    "explanation": "Batch Normalization нормализует активации на каждом слое, что стабилизирует и ускоряет обучение, а также снижает зависимость от начальных значений весов."
  },
  {
    "question": "Для какой задачи можно использовать генеративно-состязательные сети (GAN)?",
    "options": [
      "Создание реалистичных изображений",
      "Распознавание объектов",
      "Предсказание временных рядов",
      "Обнаружение аномалий"
    ],
    "explanation": "Генеративно-состязательные сети (GAN) обучаются генерировать новые данные, которые выглядят как реальные, например, изображения, видео или аудио."
  },
  {
    "question": "Какой метод используется для предотвращения градиентного взрыва в RNN?",
    "options": [
      "Обрезка градиентов (Gradient Clipping)",
      "Использование функции активации ReLU",
      "Увеличение количества слоев",
      "Dropout"
    ],
    "explanation": "Обрезка градиентов ограничивает значения градиентов заданным порогом, предотвращая их взрыв и делая обучение RNN более стабильным."
  },
  {
    "question": "Почему используют Residual Connections в глубоких сетях?",
    "options": [
      "Для борьбы с затухающими градиентами",
      "Для повышения устойчивости к шуму",
      "Для уменьшения вычислительной сложности",
      "Для улучшения разреженности весов"
    ],
    "explanation": "Residual Connections помогают бороться с затухающими градиентами, позволяя градиентам распространяться глубже в сети и улучшая обучение."
  },
  {
    "question": "Какая архитектура эффективнее для обработки временных рядов с очень длинными зависимостями?",
    "options": [
      "Transformer",
      "LSTM",
      "GRU",
      "RNN"
    ],
    "explanation": "Transformer, благодаря механизму внимания, способен эффективно обрабатывать длинные зависимости в данных, в отличие от традиционных рекуррентных сетей, таких как LSTM или GRU."
  },
  {
    "question": "В чем разница между обучением с подкреплением и супервизируемым обучением?",
    "options": [
      "В обучении с подкреплением используется сигнал вознаграждения, а не метки",
      "Обучение с подкреплением работает только с дискретными данными",
      "Супервизируемое обучение не требует функций потерь",
      "Супервизируемое обучение используется только для классификации"
    ],
    "explanation": "В обучении с подкреплением агент обучается через сигналы вознаграждения, а не через метки, как в супервизируемом обучении."
  },
  {
    "question": "Какой тип активации часто используется для выхода модели в задачах регрессии?",
    "options": [
      "Линейная активация",
      "ReLU",
      "Sigmoid",
      "Softmax"
    ],
    "explanation": "Линейная активация используется в задачах регрессии, так как она не ограничивает выходное значение и позволяет предсказывать любые числовые значения."
  },
  {
    "question": "Почему веса в нейронной сети инициализируют случайным образом, а не нулями?",
    "options": [
      "Чтобы избежать симметрии в обучении",
      "Чтобы ускорить вычисления",
      "Чтобы избежать переобучения",
      "Чтобы улучшить сходимость градиентного спуска"
    ],
    "explanation": "Инициализация весов случайным образом помогает избежать симметрии в обучении, что позволяет нейронной сети обучаться эффективно."
  },
  {
    "question": "Какой недостаток у ReLU возникает при обучении и как его можно исправить?",
    "options": [
      "«Мертвые» нейроны; использовать Leaky ReLU",
      "Взрывающиеся градиенты; применять нормализацию",
      "Отсутствие нелинейности; заменить на сигмоиду",
      "Медленное обучение; использовать Adam"
    ],
    "explanation": "Проблема «мертвых» нейронов возникает, когда ReLU даёт нулевые значения для отрицательных входов. Это можно исправить, используя Leaky ReLU."
  },
  {
    "question": "Почему градиентный спуск может застрять на плато, и как это влияет на обучение?",
    "options": [
      "Градиент становится слишком мал; обучение замедляется",
      "Градиент увеличивается; веса выходят за пределы",
      "Градиент меняет знак; возникает нестабильность",
      "Градиент не изменяется; обучение завершается"
    ],
    "explanation": "При застревании на плато градиенты становятся слишком малыми, что замедляет обучение и делает его менее эффективным."
  },
  {
    "question": "Что произойдет, если убрать bias из архитектуры сети?",
    "options": [
      "Сеть станет неспособна моделировать некоторые функции",
      "Обучение станет быстрее, но менее точным",
      "Обучение станет более устойчивым",
      "Сеть начнет переобучаться"
    ],
    "explanation": "Без bias нейронная сеть не сможет моделировать смещения, что ограничивает её способность обучаться и моделировать сложные функции."
  },
  {
    "question": "Почему LSTM могут забывать контекст, несмотря на свои механизмы управления памятью?",
    "options": [
      "Если веса плохо инициализированы или обучение нестабильно",
      "Из-за использования малых батчей",
      "Из-за отсутствия регуляризации",
      "Потому что они не поддерживают временные зависимости"
    ],
    "explanation": "Если веса LSTM не инициализированы должным образом или обучение нестабильно, то сеть может не запомнить важный контекст, несмотря на свои механизмы памяти."
  },
  {
    "question": "Как параметры оптимизатора Adam могут повлиять на устойчивость модели?",
    "options": [
      "Неправильный выбор learning rate или beta может привести к переобучению",
      "Неверные параметры могут сделать модель менее интерпретируемой",
      "Оптимизация станет быстрее, но точность снизится",
      "Модель начнет сходиться к локальным минимумам"
    ],
    "explanation": "Неправильный выбор параметров, таких как learning rate или beta, может привести к переобучению, поскольку модель может начать слишком сильно подгонять данные."
  },
  {
    "question": "Почему в глубоких сетях необходимо учитывать проблему исчезающих градиентов?",
    "options": [
      "Градиенты на верхних слоях становятся слишком малыми для обновления весов",
      "Сеть становится слишком тяжелой для вычислений",
      "Обучение замедляется из-за переполнения памяти",
      "Градиенты на нижних слоях начинают взрываться"
    ],
    "explanation": "Проблема исчезающих градиентов возникает, когда градиенты становятся слишком малыми для обновления весов в глубоких слоях сети, что замедляет обучение."
  },
  {
    "question": "Почему внимание (attention) эффективнее сверток (convolutions) в обработке текста?",
    "options": [
      "Внимание может учитывать глобальные связи между токенами",
      "Свертки требуют больше данных для обучения",
      "Внимание использует меньше памяти",
      "Свертки хуже подходят для разреженных данных"
    ],
    "explanation": "Механизм внимания позволяет модели учитывать глобальные зависимости между словами, что важно для текста, в отличие от сверток, которые фокусируются на локальных признаках."
  },
  {
    "question": "Как влияет размер батча на динамику обучения?",
    "options": [
      "Малые батчи добавляют шум, который помогает выйти из локальных минимумов",
      "Большие батчи ускоряют обучение за счет уменьшения вычислительной нагрузки",
      "Малые батчи уменьшают переобучение, но замедляют обучение",
      "Большие батчи уменьшают сходимость модели"
    ],
    "explanation": "Малые батчи добавляют шум в процесс обучения, что помогает модели выйти из локальных минимумов и улучшить обобщающую способность."
  },
  {
    "question": "Почему архитектуры трансформеров заменили рекуррентные сети в NLP?",
    "options": [
      "Они эффективнее моделируют долгосрочные зависимости благодаря механизму внимания",
      "Они требуют меньше вычислительных ресурсов",
      "Они лучше работают на маленьких выборках",
      "Они не зависят от последовательного характера данных"
    ],
    "explanation": "Архитектуры трансформеров заменили рекуррентные сети в NLP, так как они эффективнее обрабатывают долгосрочные зависимости с помощью механизма внимания."
  },
  {
    "question": "Почему регуляризация Dropout может ухудшать результаты на этапе предсказания?",
    "options": [
      "Потому что она отключает нейроны случайным образом во время обучения",
      "Потому что модель становится менее сложной",
      "Потому что модель сохраняет только обученные нейроны",
      "Потому что она увеличивает энтропию в предсказаниях"
    ],
    "explanation": "Dropout отключает случайным образом нейроны во время обучения, что предотвращает переобучение, но на этапе предсказания это может привести к ухудшению результатов."
  },
  {
    "question": "Какого результата можно достичь, если использовать слишком глубокую сеть на малом объеме данных?",
    "options": [
      "Модель может переобучиться, усваивая шум в данных",
      "Модель будет недообучена из-за слабой обобщающей способности",
      "Градиенты исчезнут, и обучение остановится",
      "Модель станет неспособна обучаться"
    ],
    "explanation": "Слишком глубокая сеть на малом объеме данных склонна к переобучению, так как она будет запоминать шум в данных, а не находить общие закономерности."
  },
  {
    "question": "Какого эффекта можно ожидать от использования сверток с большим ядром?",
    "options": [
      "Увеличение захвата глобальных признаков, но уменьшение локальной детализации",
      "Ускорение вычислений за счет уменьшения параметров",
      "Улучшение качества на мелких деталях",
      "Снижение вероятности переобучения"
    ],
    "explanation": "Большие свертки захватывают глобальные признаки, но теряют локальную детализацию, что может повлиять на точность в задачах, требующих мелких деталей."
  },
  {
    "question": "Почему метод weight decay часто применяется вместе с L2-регуляризацией?",
    "options": [
      "Для автоматического уменьшения больших весов при обновлении",
      "Для ускорения обучения",
      "Для улучшения сходимости на ранних стадиях",
      "Для снижения числа эпох обучения"
    ],
    "explanation": "Weight decay помогает автоматические уменьшать большие веса во время обучения, что предотвращает их рост и помогает улучшить обобщающую способность модели."
  },
  {
    "question": "Как изменения в архитектуре нейронной сети могут влиять на её способность к обобщению?",
    "options": [
      "Архитектура с большим количеством слоев всегда обобщает лучше",
      "Уменьшение количества параметров помогает предотвратить переобучение",
      "Большие сети всегда показывают лучшие результаты на тестовых данных",
      "Увеличение сложности модели всегда приводит к улучшению обобщающей способности"
    ],
    "explanation": "Уменьшение количества параметров и упрощение архитектуры помогают избежать переобучения, так как модель не будет слишком сильно подстраиваться под шум в обучающих данных. Важно, чтобы модель могла обобщать на новых данных, не запоминая их."
  },
  {
    "question": "Как выбор функции активации влияет на способность модели обучаться?",
    "options": [
      "Функции активации не влияют на обучение, их выбирают только для определенных типов задач",
      "ReLU может вызвать исчезновение градиентов, что замедляет обучение",
      "Sigmoid всегда приводит к взрывным градиентам при обучении глубоких сетей",
      "Правильная функция активации не имеет значения, если используется оптимизатор типа Adam"
    ],
    "explanation": "Выбор функции активации сильно влияет на процесс обучения. Например, ReLU может привести к мертвым нейронам (исчезновение градиентов), в то время как Sigmoid может ограничить градиенты и привести к проблемам с обучением в глубоких сетях."
  },
  {
    "question": "Как параметры оптимизатора (например, learning rate, beta) влияют на процесс обучения и стабильность модели?",
    "options": [
      "Слишком высокий learning rate всегда приводит к переобучению",
      "Низкий learning rate может замедлить обучение, но улучшить стабильность",
      "Слишком большие значения beta ускоряют сходимость, но могут привести к нестабильности",
      "Значения learning rate и beta не важны, если используется оптимизатор Adam"
    ],
    "explanation": "Параметры оптимизатора, такие как learning rate и beta, существенно влияют на процесс обучения. Слишком высокий learning rate может привести к переобучению и нестабильности, тогда как слишком низкий rate может замедлить сходимость, но повысить стабильность."
  },
  {
    "question": "Почему важно учитывать размер батча при обучении нейронных сетей, и как он влияет на динамику обучения?",
    "options": [
      "Малые батчи всегда приводят к лучшим результатам, так как они уменьшают переобучение",
      "Большие батчи ускоряют обучение за счет более точных оценок градиента",
      "Малые батчи добавляют шум, что может помочь избежать застревания в локальных минимумах",
      "Размер батча не имеет значения, если модель использует регуляризацию"
    ],
    "explanation": "Малые батчи могут добавить шум в процесс обучения, что помогает модели выйти из локальных минимумов, но при этом обучение может быть менее стабильным. Большие батчи обычно приводят к более точной оценке градиента, но могут увеличить вычислительные затраты."
  },
  {
    "question": "Какие особенности имеют архитектуры Transformer, и как они решают проблемы, с которыми сталкиваются другие модели для обработки текста?",
    "options": [
      "Transformer использует рекуррентные слои для работы с последовательностями",
      "Transformer эффективнее работает с долгосрочными зависимостями благодаря механизму внимания",
      "Transformer требует меньше данных для обучения, чем LSTM и GRU",
      "Transformer имеет слабую способность моделировать контекст"
    ],
    "explanation": "Transformer использует механизм внимания, который позволяет эффективно моделировать долгосрочные зависимости в данных, в отличие от рекуррентных моделей (LSTM, GRU), которые могут сталкиваться с проблемами исчезающих градиентов на больших временных промежутках."
  },
  {
    "question": "Какова роль регуляризации в нейронных сетях, и какие методы регуляризации наиболее распространены?",
    "options": [
      "Регуляризация помогает предотвратить переобучение модели",
      "Регуляризация всегда улучшает точность модели на тестовых данных",
      "Регуляризация используется для ускорения процесса обучения",
      "Методы регуляризации всегда ухудшают производительность модели на валидационных данных"
    ],
    "explanation": "Регуляризация помогает предотвратить переобучение модели, уменьшая её способность запоминать шум в данных. Популярными методами являются L2-регуляризация и Dropout."
  },
  {
    "question": "Какой из следующих методов используется для борьбы с проблемой исчезающих градиентов в глубоких нейронных сетях?",
    "options": [
      "Использование нормализации батча (Batch Normalization)",
      "Использование функции активации ReLU",
      "Использование L1-регуляризации",
      "Использование обратного распространения с момента"
    ],
    "explanation": "Использование нормализации батча помогает уменьшить проблему исчезающих градиентов, стабилизируя процесс обучения и улучшая сходимость глубоких нейронных сетей."
  },
  {
    "question": "Каким образом функция активации ReLU решает проблемы, возникающие в глубоком обучении?",
    "options": [
      "Она сохраняет градиенты, предотвращая их исчезновение на глубоких слоях",
      "Она ускоряет обучение за счет более быстрых вычислений",
      "Она способствует лучшему обучению в рекуррентных сетях",
      "Она уменьшает вычислительную сложность сети"
    ],
    "explanation": "ReLU эффективно решает проблему исчезающих градиентов, так как её производная является постоянной для положительных значений, что помогает поддерживать градиенты на более глубоких слоях сети."
  },
  {
    "question": "Почему методы оптимизации, такие как Adam, популярны в обучении глубоких сетей?",
    "options": [
      "Они используют более сложные математические модели для вычисления градиентов",
      "Они адаптируют скорость обучения для каждого параметра",
      "Они всегда приводят к лучшим результатам по сравнению с классическими методами",
      "Они не требуют применения функции потерь"
    ],
    "explanation": "Adam адаптирует скорость обучения для каждого параметра, что делает его эффективным для сложных задач и помогает ускорить сходимость, особенно при обучении глубоких сетей."
  },
  {
    "question": "Как работает Dropout и какие его преимущества?",
    "options": [
      "Он случайным образом отключает нейроны во время обучения для предотвращения переобучения",
      "Он увеличивает количество нейронов для улучшения обучения",
      "Он ускоряет процесс обучения, убирая некоторые избыточные параметры",
      "Он улучшает стабильность обучения, устраняя шум в данных"
    ],
    "explanation": "Dropout случайным образом отключает нейроны во время обучения, что помогает предотвратить переобучение, поскольку модель не может зависеть от конкретных нейронов и вынуждена использовать более обобщённые признаки."
  },
  {
    "question": "Почему в рекуррентных нейронных сетях (RNN) возникают проблемы с долгосрочными зависимостями?",
    "options": [
      "Из-за плохой инициализации весов",
      "Из-за сложности работы с большими объемами данных",
      "Из-за проблемы исчезающих и взрывающихся градиентов",
      "Из-за отсутствия регуляризации"
    ],
    "explanation": "Рекуррентные сети испытывают проблемы с долгосрочными зависимостями из-за исчезающих и взрывающихся градиентов, что затрудняет обучение на долгих последовательностях данных."
  },
  {
    "question": "Какие особенности имеет архитектура LSTM и как она помогает решать проблемы традиционных RNN?",
    "options": [
      "LSTM использует механизмы забывания и сохранения информации, что улучшает обучение на долгих последовательностях",
      "LSTM работает только с небольшими объемами данных и не подходит для больших наборов",
      "LSTM использует более глубокие нейронные сети для улучшения точности",
      "LSTM всегда обучается быстрее, чем традиционные RNN"
    ],
    "explanation": "LSTM использует специальные механизмы, такие как клетки памяти, которые помогают моделировать долгосрочные зависимости и избегать проблемы исчезающих градиентов."
  },
  {
    "question": "Как выбор функции потерь влияет на обучение модели?",
    "options": [
      "Функция потерь не влияет на процесс обучения, если используется оптимизатор типа Adam",
      "Правильная функция потерь помогает модели эффективно минимизировать ошибку на обучающих данных",
      "Функция потерь должна быть одинаковой для всех типов задач, независимо от типа модели",
      "Функция потерь влияет только на скорость обучения, но не на точность модели"
    ],
    "explanation": "Функция потерь играет ключевую роль в обучении модели, так как она определяет, насколько хороши предсказания модели по сравнению с истинными значениями. Выбор правильной функции потерь позволяет эффективно минимизировать ошибку."
  },
  {
    "question": "Каким образом нормализация данных помогает в обучении нейронных сетей?",
    "options": [
      "Нормализация помогает ускорить обучение, улучшая сходимость модели",
      "Нормализация данных всегда приводит к переобучению модели",
      "Нормализация данных уменьшает вычислительные ресурсы, требуемые для обучения",
      "Нормализация данных снижает необходимость в регуляризации"
    ],
    "explanation": "Нормализация данных помогает ускорить обучение, так как входные данные приходят в одном масштабе, что позволяет быстрее сходиться в процессе оптимизации."
  },
  {
    "question": "Почему важно использовать технику подбора гиперпараметров в процессе обучения?",
    "options": [
      "Правильный выбор гиперпараметров может значительно улучшить точность модели и ускорить её обучение",
      "Гиперпараметры не влияют на процесс обучения и могут быть случайными",
      "Гиперпараметры используются только для улучшения вычислительных затрат",
      "Правильные гиперпараметры всегда приводят к решению всех проблем с обучением"
    ],
    "explanation": "Подбор гиперпараметров позволяет найти оптимальные значения для таких параметров, как скорость обучения, размер батча и количество слоев, что влияет на эффективность и точность обучения."
  },
  {
    "question": "Как работают сверточные нейронные сети (CNN) и в чем их преимущества?",
    "options": [
      "Сверточные слои обучаются на основе случайных выборок, что ускоряет обучение",
      "CNN использует фильтры для извлечения признаков, что позволяет эффективно работать с изображениями и видео",
      "CNN применяются только в задачах классификации и не могут быть использованы в регрессии",
      "CNN требуют меньшего количества данных для обучения по сравнению с полносвязными сетями"
    ],
    "explanation": "Сверточные нейронные сети используют фильтры для извлечения локальных признаков, что делает их эффективными для работы с изображениями и видео. Это позволяет модели выделять важные признаки независимо от их расположения в пространстве."
  },
  {
    "question": "Что происходит, если модель имеет слишком много параметров по сравнению с количеством данных для обучения?",
    "options": [
      "Модель будет переобучена, так как она сможет запомнить все данные, включая шум",
      "Модель будет недообучена и не сможет захватить все закономерности",
      "Модель станет неспособной обучаться",
      "Модель быстро сойдется к оптимальному решению"
    ],
    "explanation": "Когда модель имеет слишком много параметров, она склонна к переобучению, что означает, что она будет запоминать шум в данных, вместо того чтобы обобщать закономерности."
  },
  {
    "question": "Как выбор метрики оценки модели влияет на выбор архитектуры сети?",
    "options": [
      "Метрика оценки не влияет на архитектуру сети, так как архитектура всегда остается одинаковой",
      "Метрика помогает выбрать подходящий тип модели в зависимости от задачи (например, для классификации или регрессии)",
      "Метрика влияет только на выбор функции активации в модели",
      "Метрика определяет размер сети и количество слоев"
    ],
    "explanation": "Выбор метрики оценки (например, точность, MSE) влияет на выбор модели и её архитектуры, так как разные задачи могут требовать разных типов моделей для эффективного решения."
  },
  {
    "question": "Что такое перенос обучения (transfer learning), и в каких случаях его можно использовать?",
    "options": [
      "Перенос обучения позволяет использовать данные из одной задачи для обучения другой модели на другой задаче",
      "Перенос обучения всегда приводит к переобучению, если данные не идентичны",
      "Перенос обучения работает только с малым количеством данных",
      "Перенос обучения используется для ускорения процесса калибровки модели"
    ],
    "explanation": "Перенос обучения позволяет использовать знания, полученные от одной задачи, для улучшения обучения на другой, особенно когда для второй задачи есть ограниченное количество данных."
  },
  {
    "question": "Как работает метод опорных векторов (SVM) для классификации?",
    "options": [
      "SVM ищет гиперплоскость, которая максимально разделяет классы с наибольшим зазором между ними",
      "SVM всегда использует нелинейные функции для классификации",
      "SVM работает только с малым количеством данных",
      "SVM требует обучения на больших объемах данных для точных предсказаний"
    ],
    "explanation": "Метод опорных векторов ищет гиперплоскость, которая максимально разделяет классы с наибольшим зазором между ними, что позволяет эффективно классифицировать данные."
  },
  {
    "question": "Что такое `torch.Tensor` в PyTorch и какова его роль?",
    "options": [
      "`torch.Tensor` — это многомерный массив, который хранит данные и поддерживает вычисления на GPU и CPU",
      "`torch.Tensor` — это класс, который служит для хранения изображений",
      "`torch.Tensor` — это структура данных, предназначенная только для обучения нейронных сетей",
      "`torch.Tensor` используется только для работы с текстовыми данными"
    ],
    "explanation": "`torch.Tensor` — это основной тип данных в PyTorch, представляющий собой многомерный массив, который может быть использован для хранения данных и выполнения операций на CPU и GPU."
  },
  {
    "question": "Как в PyTorch можно перемещать тензор с CPU на GPU?",
    "options": [
      "`tensor.cuda()`",
      "`tensor.to('gpu')`",
      "`tensor.move('cuda')`",
      "`tensor.on_gpu()`"
    ],
    "explanation": "Метод `tensor.cuda()` позволяет переместить тензор на GPU для ускорения вычислений, если у вас есть доступ к GPU."
  },
  {
    "question": "Что такое autograd в PyTorch?",
    "options": [
      "Модуль для автоматического дифференцирования, который автоматически вычисляет градиенты",
      "Модуль для автоматического обучения нейронных сетей",
      "Модуль для оптимизации гиперпараметров моделей",
      "Модуль для работы с данными и их подготовкой"
    ],
    "explanation": "Autograd — это система автоматического дифференцирования в PyTorch, которая отслеживает операции с тензорами и вычисляет градиенты для обратного распространения ошибки в процессе обучения."
  },
  {
    "question": "Как в PyTorch можно получить градиенты по отношению к тензору?",
    "options": [
      "`tensor.grad`",
      "`tensor.backward()`",
      "`tensor.compute_gradients()`",
      "`tensor.diff()`"
    ],
    "explanation": "После выполнения операции `tensor.backward()` PyTorch вычисляет градиенты и сохраняет их в атрибуте `tensor.grad`."
  },
  {
    "question": "Как отключить вычисление градиентов для операции в PyTorch?",
    "options": [
      "`torch.no_grad()`",
      "`tensor.detach()`",
      "`tensor.requires_grad = False`",
      "`tensor.disable_grad()`"
    ],
    "explanation": "`torch.no_grad()` или `tensor.detach()` позволяют отключить вычисление градиентов для операций, что полезно при инференсе, чтобы сэкономить память и ускорить вычисления."
  },
  {
    "question": "Что такое `nn.Module` в PyTorch?",
    "options": [
      "`nn.Module` — это базовый класс для всех нейронных сетей и слоев в PyTorch",
      "`nn.Module` — это функция для оптимизации нейронных сетей",
      "`nn.Module` — это библиотека для работы с изображениями",
      "`nn.Module` — это структура для выполнения обратного распространения ошибки"
    ],
    "explanation": "`nn.Module` — это базовый класс для всех нейронных сетей и слоев в PyTorch. Все пользовательские модели должны наследовать этот класс для правильного функционирования."
  },
  {
    "question": "Как в PyTorch инициализировать модель нейронной сети?",
    "options": [
      "Создайте класс, который наследует `nn.Module` и реализуйте метод `forward()`",
      "Используйте готовую модель из `torchvision.models`",
      "Используйте `nn.init` для инициализации весов сети",
      "Для инициализации модели достаточно вызвать `torch.nn()`"
    ],
    "explanation": "Чтобы создать модель, необходимо создать класс, который наследует `nn.Module`, и определить метод `forward()`, который описывает проход через сеть."
  },
  {
    "question": "Какую функцию в PyTorch используют для вычисления кросс-энтропийной потери для классификационных задач?",
    "options": [
      "`torch.nn.CrossEntropyLoss()`",
      "`torch.nn.MSELoss()`",
      "`torch.nn.BCELoss()`",
      "`torch.nn.NLLLoss()`"
    ],
    "explanation": "Для классификационных задач с несколькими классами используется функция потерь `torch.nn.CrossEntropyLoss()`, которая объединяет логарифм вероятности и кросс-энтропийную потерю."
  },
  {
    "question": "Как можно сохранить модель в PyTorch?",
    "options": [
      "`torch.save(model.state_dict(), 'model.pth')`",
      "`model.save('model.pth')`",
      "`torch.save(model, 'model.pth')`",
      "`model.save_state_dict('model.pth')`"
    ],
    "explanation": "Для сохранения модели в PyTorch используется метод `torch.save(model.state_dict(), 'model.pth')`, который сохраняет только параметры модели (веса), а не саму модель."
  },
  {
    "question": "Как загрузить сохраненную модель в PyTorch?",
    "options": [
      "`model.load_state_dict(torch.load('model.pth'))`",
      "`model.load('model.pth')`",
      "`model.restore('model.pth')`",
      "`torch.load('model.pth')`"
    ],
    "explanation": "Загрузить сохраненные параметры модели можно с помощью метода `model.load_state_dict(torch.load('model.pth'))`, где `'model.pth'` — это путь к файлу с сохранёнными весами."
  },
  {
    "question": "Как в PyTorch можно разделить данные на батчи?",
    "options": [
      "`torch.utils.data.DataLoader()`",
      "`torch.utils.batch.BatchLoader()`",
      "`torch.split()`",
      "`torch.data.split()`"
    ],
    "explanation": "`torch.utils.data.DataLoader()` используется для разделения данных на батчи и автоматического их поднесения в модель во время обучения."
  },
  {
    "question": "Какая функция в PyTorch используется для вычисления метрики точности (accuracy)?",
    "options": [
      "`torchmetrics.Accuracy()`",
      "`torch.nn.functional.accuracy()`",
      "`torch.accuracy()`",
      "`torchmetrics.MeanSquaredError()`"
    ],
    "explanation": "Для вычисления точности используется `torchmetrics.Accuracy()`. Это специализированная библиотека, предоставляющая методы для оценки метрик в задачах машинного обучения."
  },
  {
    "question": "Какой метод используется для применения функции активации ReLU в PyTorch?",
    "options": [
      "`torch.nn.ReLU()`",
      "`torch.relu()`",
      "`torch.nn.functional.relu()`",
      "`torch.ReLU()`"
    ],
    "explanation": "В PyTorch для применения функции активации ReLU используется `torch.nn.functional.relu()` или `torch.relu()`."
  },
  {
    "question": "Как правильно использовать GPU для обучения модели в PyTorch?",
    "options": [
      "`model.to('cuda')`",
      "`model.cuda()`",
      "`model.move('cuda')`",
      "`model.use_gpu()`"
    ],
    "explanation": "Для перемещения модели на GPU можно использовать метод `model.to('cuda')`, что позволяет обучать модель на графическом процессоре, если он доступен."
  },
  {
    "question": "Как в PyTorch работает оптимизатор?",
    "options": [
      "Оптимизатор обновляет веса модели, минимизируя функцию потерь",
      "Оптимизатор помогает избежать переобучения",
      "Оптимизатор всегда уменьшает ошибку на тестовых данных",
      "Оптимизатор уменьшает вычислительные ресурсы"
    ],
    "explanation": "Оптимизатор в PyTorch обновляет веса модели в процессе обучения, минимизируя функцию потерь с использованием различных алгоритмов (например, Adam, SGD)."
  },
  {
    "question": "Как в PyTorch можно обучить модель на нескольких GPU?",
    "options": [
      "`torch.nn.DataParallel()`",
      "`torch.nn.MultiGPU()`",
      "`torch.nn.parallel.DistributedDataParallel()`",
      "`torch.nn.GPUParallel()`"
    ],
    "explanation": "Для обучения на нескольких GPU можно использовать `torch.nn.DataParallel()`, которое распределяет вычисления по доступным GPU и объединяет их результаты."
  },
  {
    "question": "Как настроить работу с тензорами в PyTorch для обработки больших данных, которые не помещаются в память?",
    "options": [
      "Использовать функцию `torch.utils.data.DataLoader()` для загрузки данных порциями",
      "Разбить данные на несколько частей вручную и загружать их поочередно",
      "Использовать метод `tensor.split()` для разделения данных",
      "Использовать функцию `torch.load()` для прямой работы с файлами данных"
    ],
    "explanation": "Для обработки больших данных используется `torch.utils.data.DataLoader()`, который загружает данные порциями, что позволяет работать с большими объемами данных, не загружая их полностью в память."
  },
  {
    "question": "Какой метод в PyTorch позволяет задать, что тензор должен вычисляться с градиентами?",
    "options": [
      "`tensor.requires_grad_()`",
      "`tensor.requires_grad()`",
      "`tensor.set_requires_grad(True)`",
      "`tensor.grad()`"
    ],
    "explanation": "Метод `tensor.requires_grad_()` позволяет установить флаг, который указывает, что для данного тензора должны вычисляться градиенты при операции."
  },
  {
    "question": "Что делает метод `model.eval()` в PyTorch?",
    "options": [
      "Переводит модель в режим инференса, отключая обновление весов",
      "Останавливает обучение модели",
      "Переводит модель в режим тренировки",
      "Регистрирует данные для мониторинга"
    ],
    "explanation": "`model.eval()` переводит модель в режим инференса, отключая функции, такие как Dropout и BatchNorm, которые ведут себя по-разному во время тренировки и инференса."
  },
  {
    "question": "Как создать тензор, инициализированный нулями, в PyTorch?",
    "options": [
      "`torch.zeros()`",
      "`torch.zero()`",
      "`torch.empty()`",
      "`torch.zeros_like()`"
    ],
    "explanation": "Метод `torch.zeros()` создает тензор заданной формы, полностью заполненный нулями."
  },
  {
    "question": "Какой метод используется для объединения нескольких тензоров вдоль определенной оси в PyTorch?",
    "options": [
      "`torch.cat()`",
      "`torch.stack()`",
      "`torch.merge()`",
      "`torch.concat()`"
    ],
    "explanation": "Метод `torch.cat()` используется для объединения нескольких тензоров вдоль заданной оси (dimension)."
  },
  {
    "question": "Как создать тензор, заполненный случайными значениями от 0 до 1 в PyTorch?",
    "options": [
      "`torch.rand()`",
      "`torch.randn()`",
      "`torch.random()`",
      "`torch.rand_like()`"
    ],
    "explanation": "Метод `torch.rand()` создает тензор с элементами, равномерно распределенными от 0 до 1."
  },
  {
    "question": "Как PyTorch оптимизирует параметры модели при обучении?",
    "options": [
      "`Используя оптимизаторы, такие как SGD, Adam, которые обновляют веса на основе градиентов`",
      "`Используя стохастическое обновление весов`",
      "`Используя фиксированные веса на протяжении всего обучения`",
      "`Используя функции активации`"
    ],
    "explanation": "Оптимизаторы, такие как SGD или Adam, обновляют параметры модели на основе вычисленных градиентов, минимизируя функцию потерь."
  },
  {
    "question": "Как можно обновить веса нейронной сети с использованием градиентов в PyTorch?",
    "options": [
      "`Используя метод `optimizer.step()` после вызова `loss.backward()`",
      "`Используя метод `model.update()`",
      "`Используя метод `model.step()`",
      "`Используя метод `optimizer.update()`"
    ],
    "explanation": "После вычисления градиентов с помощью `loss.backward()`, вызов `optimizer.step()` обновляет параметры модели на основе этих градиентов."
  },
  {
    "question": "Что такое `torch.nn.functional` в PyTorch?",
    "options": [
      "Модуль, содержащий функции для работы с тензорами и слоями, такие как активации, потери и т.д.",
      "Модуль для работы с внешними библиотеками",
      "Модуль для работы с функциями потерь",
      "Модуль для визуализации данных"
    ],
    "explanation": "`torch.nn.functional` содержит функции для работы с тензорами и слоями, такие как функции активации, потери, свертки и другие операции."
  },
  {
    "question": "Как задать тип данных тензора в PyTorch?",
    "options": [
      "`tensor.to(dtype)`",
      "`tensor.type(dtype)`",
      "`tensor.convert(dtype)`",
      "`tensor.set_type(dtype)`"
    ],
    "explanation": "Метод `tensor.to(dtype)` позволяет изменить тип данных тензора. Можно также использовать `tensor.type(dtype)`."
  },
  {
    "question": "Что такое `torchvision` в контексте PyTorch?",
    "options": [
      "Библиотека для обработки и трансформации изображений",
      "Библиотека для обработки текстов",
      "Библиотека для работы с графами",
      "Библиотека для работы с аудио"
    ],
    "explanation": "`torchvision` — это библиотека для обработки и трансформации изображений, которая также включает в себя предобученные модели для задач компьютерного зрения."
  },
  {
    "question": "Как выполнить обратное распространение ошибки в PyTorch?",
    "options": [
      "`tensor.backward()`",
      "`optimizer.backward()`",
      "`model.backward()`",
      "`loss.backward()`"
    ],
    "explanation": "Для выполнения обратного распространения ошибки необходимо вызвать `loss.backward()`, где `loss` — это вычисленная функция потерь."
  },
  {
    "question": "Какой метод используется для деления данных на обучающую и тестовую выборки в PyTorch?",
    "options": [
      "`torch.utils.data.random_split()`",
      "`torch.split()`",
      "`torch.train_test_split()`",
      "`torch.dataset_split()`"
    ],
    "explanation": "`torch.utils.data.random_split()` используется для случайного разделения данных на обучающие и тестовые выборки."
  },
  {
    "question": "Что такое `DataLoader` в PyTorch?",
    "options": [
      "Класс для эффективной загрузки данных и формирования батчей",
      "Класс для работы с данными, подготовленными для тренировки",
      "Класс для подбора гиперпараметров модели",
      "Класс для обработки изображений"
    ],
    "explanation": "`DataLoader` используется для загрузки данных, их пакетирования в батчи, перемешивания и итерации по ним в процессе обучения модели."
  },
  {
    "question": "Как в PyTorch задать функцию активации ReLU?",
    "options": [
      "`torch.nn.ReLU()`",
      "`torch.nn.functional.relu()`",
      "`torch.relu()`",
      "`torch.relu_activation()`"
    ],
    "explanation": "Функцию активации ReLU можно задать как `torch.nn.ReLU()` или использовать функциональную версию `torch.nn.functional.relu()`."
  },
  {
    "question": "Как в PyTorch добавить новый слой в модель?",
    "options": [
      "`Используя классы из `torch.nn` для создания слоев и добавляя их в `nn.Module`",
      "`Просто добавив слой как атрибут модели`",
      "`Используя метод `add_layer()` в классе `nn.Module`",
      "`Добавив слой в функцию `forward()`"
    ],
    "explanation": "Новый слой можно добавить, используя классы из `torch.nn` для создания слоев и добавляя их в `nn.Module` модели."
  },
  {
    "question": "Как в PyTorch можно использовать метод `apply()`?",
    "options": [
      "`Для применения функции ко всем параметрам модели",
      "`Для применения функции ко всем тензорам в слое`",
      "`Для оптимизации модели`",
      "`Для определения параметров слоев модели`"
    ],
    "explanation": "Метод `apply()` в PyTorch используется для применения функции ко всем параметрам модели, что может быть полезно для инициализации весов или других настроек."
  },
  {
    "question": "Как в PyTorch вычисляется градиент для сложных функций?",
    "options": [
      "`Используется цепное правило дифференцирования, которое отслеживает операции с тензорами`",
      "`Используется прямой метод дифференцирования`",
      "`Градиенты вычисляются вручную в каждой функции`",
      "`Градиенты не вычисляются для сложных функций`"
    ],
    "explanation": "В PyTorch используется цепное правило дифференцирования для автоматического вычисления градиентов через операции с тензорами."
  },
  {
    "question": "Как реализовать сверточный слой в PyTorch?",
    "options": [
      "`Использовать `torch.nn.Conv2d()` для 2D свертки`",
      "`Использовать `torch.nn.Conv1d()` для 1D свертки`",
      "`Использовать `torch.nn.Conv3d()` для 3D свертки`",
      "`Все выше перечисленные варианты`"
    ],
    "explanation": "В PyTorch сверточные слои для 1D, 2D и 3D данных реализуются с помощью `torch.nn.Conv1d()`, `torch.nn.Conv2d()` и `torch.nn.Conv3d()`, соответственно."
  },
  {
    "question": "Какой метод используется для обновления гиперпараметров в PyTorch?",
    "options": [
      "`Используется оптимизатор, например, `torch.optim.Adam` или `torch.optim.SGD`",
      "`Используется метод `optimizer.update_hyperparameters()`",
      "`Гиперпараметры не обновляются в PyTorch`",
      "`Используется функция `torch.update()`"
    ],
    "explanation": "Гиперпараметры обновляются в PyTorch через оптимизаторы, такие как `torch.optim.Adam` или `torch.optim.SGD`."
  },
  {
    "question": "Как создать массив NumPy, заполненный нулями?",
    "options": [
      "`np.zeros()`",
      "`np.zero()`",
      "`np.empty()`",
      "`np.fill(0)`"
    ],
    "explanation": "Метод `np.zeros()` используется для создания массива заданной формы, заполненного нулями."
  },
  {
    "question": "Как создать массив NumPy с элементами, равномерно распределенными в заданном диапазоне?",
    "options": [
      "`np.linspace()`",
      "`np.arange()`",
      "`np.random.uniform()`",
      "`np.random.randn()`"
    ],
    "explanation": "Метод `np.linspace()` создает массив с элементами, равномерно распределенными в заданном диапазоне."
  },
  {
    "question": "Как проверить размерность массива NumPy?",
    "options": [
      "`np.ndim()`",
      "`arr.shape()`",
      "`arr.ndim`",
      "`arr.size()`"
    ],
    "explanation": "Для проверки размерности массива NumPy используется атрибут `ndim`."
  },
  {
    "question": "Как создать матрицу идентичности в NumPy?",
    "options": [
      "`np.eye()`",
      "`np.identity()`",
      "`np.ident()`",
      "`np.identity_matrix()`"
    ],
    "explanation": "Метод `np.eye()` создает матрицу идентичности заданного размера."
  },
  {
    "question": "Как создать массив с случайными целыми числами в NumPy?",
    "options": [
      "`np.random.randint()`",
      "`np.random.randn()`",
      "`np.random.random()`",
      "`np.random.uniform()`"
    ],
    "explanation": "Метод `np.random.randint()` генерирует массив случайных целых чисел в заданном диапазоне."
  },
  {
    "question": "Как изменить размерность массива в NumPy?",
    "options": [
      "`arr.reshape()`",
      "`arr.resize()`",
      "`np.resize()`",
      "`arr.reformat()`"
    ],
    "explanation": "Метод `arr.reshape()` позволяет изменить размерность массива, не изменяя его содержимого."
  },
  {
    "question": "Как объединить два массива в NumPy по оси 0?",
    "options": [
      "`np.vstack()`",
      "`np.hstack()`",
      "`np.concatenate()`",
      "`np.stack()`"
    ],
    "explanation": "Метод `np.vstack()` используется для вертикального объединения массивов (по оси 0)."
  },
  {
    "question": "Как вычислить среднее значение элементов массива NumPy?",
    "options": [
      "`np.mean()`",
      "`np.average()`",
      "`np.sum()`",
      "`np.median()`"
    ],
    "explanation": "Метод `np.mean()` вычисляет среднее значение элементов массива."
  },
  {
    "question": "Как извлечь уникальные элементы из массива NumPy?",
    "options": [
      "`np.unique()`",
      "`np.distinct()`",
      "`np.difference()`",
      "`np.extract_unique()`"
    ],
    "explanation": "Метод `np.unique()` возвращает массив уникальных элементов из исходного массива."
  },
  {
    "question": "Как преобразовать массив в одномерный в NumPy?",
    "options": [
      "`arr.flatten()`",
      "`arr.reshape(-1)`",
      "`arr.ravel()`",
      "`arr.convert()`"
    ],
    "explanation": "Методы `arr.flatten()` и `arr.ravel()` преобразуют массив в одномерный. `reshape(-1)` также работает для этой цели."
  },
  {
    "question": "Как получить транспонированную версию матрицы в NumPy?",
    "options": [
      "`arr.T`",
      "`np.transpose(arr)`",
      "`arr.transpose()`",
      "`arr.transposed()`"
    ],
    "explanation": "Для получения транспонированной версии массива используется атрибут `arr.T` или метод `np.transpose(arr)`."
  },
  {
    "question": "Как в NumPy вычислить стандартное отклонение элементов массива?",
    "options": [
      "`np.std()`",
      "`np.var()`",
      "`np.deviation()`",
      "`np.sqrt()`"
    ],
    "explanation": "Метод `np.std()` вычисляет стандартное отклонение элементов массива."
  },
  {
    "question": "Как задать фиксированный тип данных для массива NumPy?",
    "options": [
      "`np.array(dtype)`",
      "`np.astype()`",
      "`arr.set_type()`",
      "`arr.convert_type()`"
    ],
    "explanation": "При создании массива можно задать тип данных с помощью параметра `dtype`, или использовать метод `arr.astype()` для преобразования типа данных уже существующего массива."
  },
  {
    "question": "Как получить индексы максимальных значений в массиве NumPy?",
    "options": [
      "`np.argmax()`",
      "`np.max()`",
      "`np.index_max()`",
      "`np.argmax()`"
    ],
    "explanation": "Метод `np.argmax()` возвращает индексы максимальных значений в массиве."
  },
  {
    "question": "Как использовать NumPy для выполнения операции element-wise (поэлементного) сложения двух массивов?",
    "options": [
      "`arr1 + arr2`",
      "`np.add(arr1, arr2)`",
      "`arr1.add(arr2)`",
      "`np.sum(arr1, arr2)`"
    ],
    "explanation": "Операция поэлементного сложения массивов может быть выполнена как `arr1 + arr2` или с помощью функции `np.add(arr1, arr2)`."
  },
  {
    "question": "Как в NumPy создать массив с случайными значениями из нормального распределения?",
    "options": [
      "`np.random.randn()`",
      "`np.random.normal()`",
      "`np.random.random()`",
      "`np.random.uniform()`"
    ],
    "explanation": "Метод `np.random.randn()` генерирует случайные значения, распределенные по стандартному нормальному закону."
  },
  {
    "question": "Как изменить все элементы массива NumPy, умножив их на 2?",
    "options": [
      "`arr * 2`",
      "`np.multiply(arr, 2)`",
      "`arr.times(2)`",
      "`arr.scale(2)`"
    ],
    "explanation": "Можно умножить все элементы массива на 2 с помощью операции `arr * 2` или функции `np.multiply(arr, 2)`."
  },
  {
    "question": "Как вычислить ковариацию между двумя массивами в NumPy?",
    "options": [
      "`np.cov()`",
      "`np.corrcoef()`",
      "`np.covariance()`",
      "`np.var()`"
    ],
    "explanation": "Метод `np.cov()` вычисляет ковариацию между двумя массивами."
  },
  {
    "question": "Как в NumPy получить срез массива?",
    "options": [
      "`arr[start:end]`",
      "`arr.slice(start, end)`",
      "`arr.cut(start, end)`",
      "`arr.extract(start, end)`"
    ],
    "explanation": "Для получения среза массива используется стандартный синтаксис Python: `arr[start:end]`."
  },
  {
    "question": "Как создать копию массива в NumPy?",
    "options": [
      "`arr.copy()`",
      "`np.copy(arr)`",
      "`arr.duplicate()`",
      "`arr.clone()`"
    ],
    "explanation": "Для создания копии массива используется метод `arr.copy()`."
  },
  {
    "question": "Как в NumPy создать массив с одинаковыми значениями?",
    "options": [
      "`np.full()`",
      "`np.ones()`",
      "`np.repeat()`",
      "`np.fill()`"
    ],
    "explanation": "Метод `np.full()` позволяет создать массив с заданными размерами, заполненный одинаковыми значениями."
  },
  {
    "question": "Как в NumPy применить логарифм ко всем элементам массива?",
    "options": [
      "`np.log()`",
      "`np.exp()`",
      "`np.log10()`",
      "`np.pow()`"
    ],
    "explanation": "Метод `np.log()` применяет натуральный логарифм ко всем элементам массива."
  },
  {
    "question": "Как в NumPy выполнить поэлементное умножение двух массивов?",
    "options": [
      "`arr1 * arr2`",
      "`np.multiply(arr1, arr2)`",
      "`arr1.dot(arr2)`",
      "`arr1.times(arr2)`"
    ],
    "explanation": "Поэлементное умножение выполняется с помощью `arr1 * arr2` или функции `np.multiply(arr1, arr2)`."
  },
  {
    "question": "Как выполнить поэлементное деление двух массивов в NumPy?",
    "options": [
      "`arr1 / arr2`",
      "`np.divide(arr1, arr2)`",
      "`arr1.div(arr2)`",
      "`arr1.split(arr2)`"
    ],
    "explanation": "Поэлементное деление выполняется с помощью `arr1 / arr2` или функции `np.divide(arr1, arr2)`."
  },
  {
    "question": "Как в NumPy вычислить медиану массива?",
    "options": [
      "`np.median()`",
      "`np.mean()`",
      "`np.average()`",
      "`np.mode()`"
    ],
    "explanation": "Метод `np.median()` вычисляет медиану массива."
  },
  {
    "question": "Как в NumPy извлечь индексы минимальных значений в массиве?",
    "options": [
      "`np.argmin()`",
      "`np.min()`",
      "`np.index_min()`",
      "`np.find_min()`"
    ],
    "explanation": "Метод `np.argmin()` возвращает индексы минимальных значений в массиве."
  },
  {
    "question": "Как в NumPy сделать случайную выборку с возвратом?",
    "options": [
      "`np.random.choice()`",
      "`np.random.sample()`",
      "`np.random.randint()`",
      "`np.random.shuffle()`"
    ],
    "explanation": "Метод `np.random.choice()` используется для случайной выборки с возвратом."
  },
  {
    "question": "Как в NumPy создать двумерный массив, где все элементы равны единице?",
    "options": [
      "`np.ones()`",
      "`np.full()`",
      "`np.empty()`",
      "`np.identity()`"
    ],
    "explanation": "Метод `np.ones()` создает двумерный массив, все элементы которого равны единице."
  },
  {
    "question": "Как в NumPy транспонировать массив на месте?",
    "options": [
      "`arr.T`",
      "`arr.transpose()`",
      "`arr.swapaxes()`",
      "`arr.transpose(inplace=True)`"
    ],
    "explanation": "Атрибут `arr.T` или метод `arr.transpose()` используется для транспонирования массива."
  },
  {
    "question": "Как вычислить разницу между соседними элементами массива в NumPy?",
    "options": [
      "`np.diff()`",
      "`np.diff_elements()`",
      "`np.diff()`",
      "`arr.difference()`"
    ],
    "explanation": "Функция `np.diff()` вычисляет разницу между соседними элементами массива."
  },
  {
    "question": "Как создать массив из случайных значений в интервале [0, 1) в NumPy?",
    "options": [
      "`np.random.random()`",
      "`np.random.uniform(0, 1)`",
      "`np.random.randint()`",
      "`np.random.randn()`"
    ],
    "explanation": "Метод `np.random.random()` генерирует массив случайных значений в интервале [0, 1)."
  },
  {
    "question": "Как вычислить скалярное произведение двух массивов в NumPy?",
    "options": [
      "`np.dot()`",
      "`np.cross()`",
      "`np.inner()`",
      "`np.multiply()`"
    ],
    "explanation": "Метод `np.dot()` вычисляет скалярное произведение двух массивов."
  },
  {
    "question": "Как выполнить поэлементную операцию возведения элементов массива в степень?",
    "options": [
      "`np.power()`",
      "`arr ** n`",
      "`np.exp()`",
      "`arr.exp()`"
    ],
    "explanation": "Для поэлементного возведения в степень можно использовать `np.power()` или оператор `**`."
  },
  {
    "question": "Как в NumPy создать случайный массив нормального распределения?",
    "options": [
      "`np.random.randn()`",
      "`np.random.normal()`",
      "`np.random.gauss()`",
      "`np.random.random()`"
    ],
    "explanation": "Метод `np.random.randn()` генерирует случайный массив с элементами, распределенными по стандартному нормальному распределению."
  },
  {
    "question": "Как объединить два массива вдоль оси 1 (по столбцам)?",
    "options": [
      "`np.hstack()`",
      "`np.vstack()`",
      "`np.concatenate()`",
      "`np.join()`"
    ],
    "explanation": "Для объединения массивов вдоль оси 1 (по столбцам) используется `np.hstack()` или `np.concatenate()` с параметром `axis=1`."
  },
  {
    "question": "Как в NumPy вычислить сумму по столбцам двумерного массива?",
    "options": [
      "`np.sum(axis=0)`",
      "`np.sum(axis=1)`",
      "`np.column_sum()`",
      "`np.row_sum()`"
    ],
    "explanation": "Для вычисления суммы по столбцам двумерного массива используется `np.sum(axis=0)`."
  },
  {
    "question": "Как в NumPy вычислить сумму по строкам двумерного массива?",
    "options": [
      "`np.sum(axis=1)`",
      "`np.sum(axis=0)`",
      "`np.row_sum()`",
      "`np.column_sum()`"
    ],
    "explanation": "Для вычисления суммы по строкам двумерного массива используется `np.sum(axis=1)`."
  },
  {
    "question": "Как в NumPy создать случайный массив с нормальным распределением с заданными параметрами?",
    "options": [
      "`np.random.normal(loc, scale, size)`",
      "`np.random.randn(size)`",
      "`np.random.random(size)`",
      "`np.random.uniform(low, high, size)`"
    ],
    "explanation": "Метод `np.random.normal(loc, scale, size)` позволяет создать массив случайных чисел с нормальным распределением с указанными параметрами."
  },
  {
    "question": "Как в Seaborn построить простую гистограмму?",
    "options": [
      "`sns.histplot()`",
      "`sns.barplot()`",
      "`sns.boxplot()`",
      "`sns.lineplot()`"
    ],
    "explanation": "Для построения гистограммы в Seaborn используется функция `sns.histplot()`."
  },
  {
    "question": "Как в Seaborn визуализировать зависимость между двумя числовыми переменными?",
    "options": [
      "`sns.scatterplot()`",
      "`sns.lineplot()`",
      "`sns.barplot()`",
      "`sns.violinplot()`"
    ],
    "explanation": "Для визуализации зависимости между двумя числовыми переменными используется `sns.scatterplot()`."
  },
  {
    "question": "Как в Seaborn создать тепловую карту (heatmap)?",
    "options": [
      "`sns.heatmap()`",
      "`sns.heatmapplot()`",
      "`sns.heatmapgraph()`",
      "`sns.matrixplot()`"
    ],
    "explanation": "Для создания тепловой карты используется функция `sns.heatmap()`."
  },
  {
    "question": "Как в Seaborn построить pairplot для набора данных?",
    "options": [
      "`sns.pairplot()`",
      "`sns.pairwiseplot()`",
      "`sns.multi_plot()`",
      "`sns.plotpair()`"
    ],
    "explanation": "Для построения парных графиков используется функция `sns.pairplot()`."
  },
  {
    "question": "Как в Seaborn изменить цветовую палитру графиков?",
    "options": [
      "`sns.set_palette()`",
      "`sns.set_colors()`",
      "`sns.set_style()`",
      "`sns.set_theme()`"
    ],
    "explanation": "Для изменения цветовой палитры графиков используется `sns.set_palette()`."
  },
  {
    "question": "Как в Matplotlib задать сетку на графике?",
    "options": [
      "`plt.grid(True)`",
      "`plt.show_grid()`",
      "`plt.set_grid()`",
      "`plt.add_grid()`"
    ],
    "explanation": "Для добавления сетки на график в Matplotlib используется `plt.grid(True)`."
  },
  {
    "question": "Как в Matplotlib добавить заголовок к графику?",
    "options": [
      "`plt.title()`",
      "`plt.set_title()`",
      "`plt.header()`",
      "`plt.title_graph()`"
    ],
    "explanation": "Для добавления заголовка на график используется `plt.title()`."
  },
  {
    "question": "Как в Seaborn настроить отображение диагональных графиков в `pairplot`?",
    "options": [
      "`diag_kind='kde'`",
      "`diag_kind='hist'`",
      "`diag_kind='scatter'`",
      "`diag_kind='box'`"
    ],
    "explanation": "Для настройки типа диагональных графиков в `pairplot` используется параметр `diag_kind`, который может быть 'kde', 'hist' и другие."
  },
  {
    "question": "Как в Matplotlib изменить размер шрифта на графике?",
    "options": [
      "`plt.rcParams['font.size']`",
      "`plt.fontsize()`",
      "`plt.set_fontsize()`",
      "`plt.text_font()`"
    ],
    "explanation": "Для изменения размера шрифта на графике в Matplotlib используется параметр `plt.rcParams['font.size']`."
  },
  {
    "question": "Как в Seaborn построить график для отображения распределения одной переменной?",
    "options": [
      "`sns.distplot()`",
      "`sns.lineplot()`",
      "`sns.boxplot()`",
      "`sns.barplot()`"
    ],
    "explanation": "Для отображения распределения одной переменной используется функция `sns.distplot()`."
  },
  {
    "question": "Как в Seaborn добавить линии тренда к графику рассеяния?",
    "options": [
      "`sns.regplot()`",
      "`sns.lineplot()`",
      "`sns.trendline()`",
      "`sns.scatterplot()`"
    ],
    "explanation": "Для добавления линий тренда на график рассеяния используется функция `sns.regplot()`."
  },
  {
    "question": "Как в Matplotlib изменить стиль линий на графике?",
    "options": [
      "`plt.plot(style='--')`",
      "`plt.set_line_style()`",
      "`plt.set_linestyle()`",
      "`plt.line_style()`"
    ],
    "explanation": "Для изменения стиля линий используется параметр `style` в функции `plt.plot()`, например, `style='--'` для пунктирной линии."
  },
  {
    "question": "Как в Seaborn создать график для отображения распределения нескольких переменных?",
    "options": [
      "`sns.kdeplot()`",
      "`sns.histplot()`",
      "`sns.pairplot()`",
      "`sns.violinplot()`"
    ],
    "explanation": "Для отображения распределения нескольких переменных можно использовать `sns.kdeplot()` или `sns.pairplot()`."
  },
  {
    "question": "Как в Matplotlib изменить цвет графика?",
    "options": [
      "`plt.plot(color='red')`",
      "`plt.set_color()`",
      "`plt.color()`",
      "`plt.plot_color()`"
    ],
    "explanation": "Цвет графика можно изменить, передав параметр `color` в функцию `plt.plot()`, например, `color='red'`."
  },
  {
    "question": "Как в Matplotlib добавить метки к осям графика?",
    "options": [
      "`plt.xlabel(), plt.ylabel()`",
      "`plt.set_xlabel(), plt.set_ylabel()`",
      "`plt.add_xlabel(), plt.add_ylabel()`",
      "`plt.axis_labels()`"
    ],
    "explanation": "Метки осей можно добавить с помощью функций `plt.xlabel()` и `plt.ylabel()`."
  },
  {
    "question": "Как в Seaborn настроить стиль графиков?",
    "options": [
      "`sns.set_style()`",
      "`sns.set_theme()`",
      "`sns.set_mode()`",
      "`sns.set_plot_style()`"
    ],
    "explanation": "Для настройки стиля графиков в Seaborn используется `sns.set_style()`."
  },
  {
    "question": "Как в Seaborn построить диаграмму размаха (boxplot)?",
    "options": [
      "`sns.boxplot()`",
      "`sns.scatterplot()`",
      "`sns.violinplot()`",
      "`sns.histplot()`"
    ],
    "explanation": "Для построения диаграммы размаха используется функция `sns.boxplot()`."
  },
  {
    "question": "Как в Matplotlib сохранить график в файл?",
    "options": [
      "`plt.savefig('filename.png')`",
      "`plt.save('filename.png')`",
      "`plt.write('filename.png')`",
      "`plt.export('filename.png')`"
    ],
    "explanation": "Для сохранения графика в файл используется функция `plt.savefig('filename.png')`."
  },
  {
    "question": "Как в Seaborn построить график для отображения взаимосвязи между несколькими категориальными переменными?",
    "options": [
      "`sns.catplot()`",
      "`sns.pairplot()`",
      "`sns.scatterplot()`",
      "`sns.boxplot()`"
    ],
    "explanation": "Для отображения взаимосвязи между несколькими категориальными переменными используется функция `sns.catplot()`."
  },
  {
    "question": "Как в Matplotlib изменить прозрачность графика?",
    "options": [
      "`plt.plot(alpha=0.5)`",
      "`plt.set_alpha(0.5)`",
      "`plt.transparency(0.5)`",
      "`plt.plot_transparency(0.5)`"
    ],
    "explanation": "Прозрачность графика можно изменить с помощью параметра `alpha`, например, `plt.plot(alpha=0.5)`."
  },
  {
    "question": "На какой архитектуре основана модель BERT и для каких задач она используется?",
    "options": [
      "На архитектуре Transformer; используется для обработки текста",
      "На архитектуре LSTM; используется для обработки временных рядов",
      "На архитектуре CNN; используется для изображений",
      "На архитектуре GAN; используется для генерации данных"
    ],
    "explanation": "BERT основан на архитектуре Transformer и используется в основном для обработки текста, включая задачи классификации, извлечения информации и перевода."
  },
  {
    "question": "Что делает модель GAN (Generative Adversarial Network)?",
    "options": [
      "Генерирует новые данные, обучаясь на реальных примерах",
      "Обрабатывает временные ряды для предсказания будущих значений",
      "Классифицирует изображения с высокой точностью",
      "Предсказывает вероятностные распределения для данных"
    ],
    "explanation": "GAN генерирует новые данные (например, изображения), обучаясь на реальных примерах, с использованием двух сетей — генератора и дискриминатора."
  },
  {
    "question": "Какую задачу решает модель LSTM (Long Short-Term Memory)?",
    "options": [
      "Обработка временных рядов с длительными зависимостями",
      "Генерация текста на основе словаря",
      "Предсказание будущих событий на основе фиксированного контекста",
      "Классификация изображений"
    ],
    "explanation": "LSTM используется для обработки временных рядов и последовательностей с длительными зависимостями, например, для задач прогнозирования или перевода текста."
  },
  {
    "question": "Для каких целей используется модель ResNet?",
    "options": [
      "Для классификации изображений с помощью глубоких сверточных сетей",
      "Для генерации изображений с нуля",
      "Для обработки текста и синтаксического анализа",
      "Для регрессии временных рядов"
    ],
    "explanation": "ResNet (Residual Networks) используется для классификации изображений и позволяет обучать очень глубокие сети благодаря использованию остаточных связей."
  },
  {
    "question": "Что такое модель Transformer и какие задачи она решает?",
    "options": [
      "Модель, основанная на механизме внимания, используемая для обработки последовательностей, таких как текст",
      "Модель для классификации изображений, основанная на сверточных слоях",
      "Модель для обработки числовых данных, использующая LSTM",
      "Модель для прогнозирования временных рядов"
    ],
    "explanation": "Transformer использует механизм внимания и широко применяется для обработки последовательностей данных, таких как текст, в задачах перевода, классификации и понимания текста."
  },
  {
    "question": "Для чего используются сверточные нейронные сети (CNN)?",
    "options": [
      "Для обработки изображений и извлечения признаков",
      "Для работы с текстом в задачах классификации",
      "Для прогнозирования временных рядов",
      "Для генерации новых данных"
    ],
    "explanation": "Сверточные нейронные сети (CNN) эффективно используются для обработки изображений, таких как распознавание объектов, анализ текстур и классификация."
  },
  {
    "question": "Какая модель используется для решения задач с последовательными зависимостями, например, машинного перевода?",
    "options": [
      "RNN (Recurrent Neural Network)",
      "CNN (Convolutional Neural Network)",
      "ResNet",
      "SVM (Support Vector Machine)"
    ],
    "explanation": "Для задач с последовательными зависимостями, например, машинного перевода, используются RNN и её более продвинутые версии, такие как LSTM и GRU."
  },
  {
    "question": "Что такое модель VAE (Variational Autoencoder) и для чего она используется?",
    "options": [
      "Для генерации данных, например, изображений, на основе скрытого пространства",
      "Для классификации изображений",
      "Для обработки временных рядов",
      "Для улучшения качества изображений с помощью увеличения резкости"
    ],
    "explanation": "VAE (Variational Autoencoder) используется для генерации данных, таких как изображения, путём изучения скрытого пространства данных."
  },
  {
    "question": "Что такое модель XGBoost и для чего она используется?",
    "options": [
      "Для решения задач классификации и регрессии с помощью градиентного бустинга",
      "Для обработки изображений с помощью сверточных сетей",
      "Для генерации текста с использованием RNN",
      "Для предсказания временных рядов с помощью LSTM"
    ],
    "explanation": "XGBoost — это алгоритм градиентного бустинга, который используется для задач классификации и регрессии, обеспечивая высокую точность."
  },
  {
    "question": "Что такое модель T5 (Text-to-Text Transfer Transformer)?",
    "options": [
      "Модель, преобразующая любые задачи NLP в задачу преобразования текста в текст",
      "Модель для классификации изображений",
      "Модель для обработки временных рядов",
      "Модель для генерации музыки"
    ],
    "explanation": "T5 использует архитектуру Transformer и преобразует любые задачи обработки текста (перевод, классификация, извлечение информации) в задачу преобразования текста в текст."
  },
  {
    "question": "Какую задачу решает модель U-Net?",
    "options": [
      "Сегментация изображений",
      "Классификация изображений",
      "Генерация изображений",
      "Обработка временных рядов"
    ],
    "explanation": "U-Net применяется для сегментации изображений, особенно в медицинских задачах, где нужно выделить объекты из изображений, например, клетки или органы."
  },
  {
    "question": "Какую задачу решает модель BART (Bidirectional and Auto-Regressive Transformers)?",
    "options": [
      "Используется для задач генерации и обработки текста, таких как переводы и резюмирование",
      "Предсказывает временные ряды с использованием RNN",
      "Генерирует изображения с помощью GAN",
      "Решает задачи классификации с использованием CNN"
    ],
    "explanation": "BART используется для задач генерации и обработки текста, таких как переводы, резюмирование и восстановление текста."
  },
  {
    "question": "Что такое модель FastText и как она используется?",
    "options": [
      "Модель для быстрого обучения векторных представлений слов и их классификации",
      "Модель для генерации текста",
      "Модель для обработки изображений с помощью CNN",
      "Модель для сегментации текстов"
    ],
    "explanation": "FastText — это модель для обучения векторных представлений слов, которая также может использоваться для классификации текста."
  },
  {
    "question": "Для чего используется модель DeepLab v3?",
    "options": [
      "Для семантической сегментации изображений",
      "Для обработки временных рядов",
      "Для классификации текстов",
      "Для генерации новых изображений"
    ],
    "explanation": "DeepLab v3 используется для семантической сегментации изображений, т.е. для выделения объектов на изображении."
  },
  {
    "question": "Какая модель используется для обучения на основе представлений и обеспечения переносного обучения?",
    "options": [
      "SimCLR (Simple Contrastive Learning of Representations)",
      "VAE (Variational Autoencoder)",
      "LSTM (Long Short-Term Memory)",
      "SVM (Support Vector Machine)"
    ],
    "explanation": "SimCLR используется для обучения на основе представлений, используя контрастивное обучение для извлечения полезных признаков."
  },
  {
    "question": "Что такое модель YOLO (You Only Look Once) и для чего она используется?",
    "options": [
      "Для обнаружения объектов в изображениях и видео",
      "Для сегментации изображений",
      "Для классификации временных рядов",
      "Для генерации текстов"
    ],
    "explanation": "YOLO используется для обнаружения объектов в изображениях и видео в реальном времени."
  },
  {
    "question": "Какую задачу решает модель TCN (Temporal Convolutional Network)?",
    "options": [
      "Обработка временных рядов с помощью сверточных слоев",
      "Классификация изображений с помощью CNN",
      "Генерация текста с помощью LSTM",
      "Обнаружение объектов в изображениях с помощью CNN"
    ],
    "explanation": "TCN используется для обработки временных рядов с помощью сверточных слоев, заменяя традиционные RNN."
  },
  {
    "question": "Для чего используется модель EfficientNet?",
    "options": [
      "Для классификации изображений с высокой эффективностью",
      "Для генерации изображений",
      "Для обработки текста",
      "Для анализа временных рядов"
    ],
    "explanation": "EfficientNet используется для классификации изображений, при этом она отличается высокой эффективностью благодаря оптимизированной архитектуре."
  },
  {
    "question": "Какую модель вы бы использовали для классификации изображений?",
    "options": [
      "ResNet",
      "BERT",
      "LSTM",
      "XGBoost"
    ],
    "explanation": "Для классификации изображений лучше всего подходят сверточные нейронные сети, такие как ResNet, которые эффективны для извлечения признаков из изображений."
  },
  {
    "question": "Какую модель следует использовать для задачи обработки текста, например, для перевода с одного языка на другой?",
    "options": [
      "Transformer",
      "CNN",
      "LSTM",
      "XGBoost"
    ],
    "explanation": "Для задач обработки текста, таких как машинный перевод, архитектура Transformer является наиболее эффективной, так как она использует механизм внимания для обработки длинных зависимостей в тексте."
  },
  {
    "question": "Какую модель вы бы использовали для генерации изображений?",
    "options": [
      "GAN",
      "SVM",
      "ResNet",
      "RNN"
    ],
    "explanation": "Для генерации изображений подходит модель GAN (Generative Adversarial Network), которая состоит из двух сетей: генератора и дискриминатора, обучающихся в процессе состязания."
  },
  {
    "question": "Какая модель лучше всего подходит для обработки временных рядов и прогнозирования на основе предыдущих данных?",
    "options": [
      "LSTM",
      "ResNet",
      "BERT",
      "XGBoost"
    ],
    "explanation": "LSTM (Long Short-Term Memory) идеально подходит для работы с временными рядами, так как она учитывает долгосрочные зависимости в данных."
  },
  {
    "question": "Какую модель вы бы использовали для сегментации изображений (например, выделение опухолей на медицинских снимках)?",
    "options": [
      "U-Net",
      "GAN",
      "BERT",
      "XGBoost"
    ],
    "explanation": "U-Net используется для сегментации изображений, например, для выделения объектов на медицинских снимках, так как она эффективно обучается с небольшими размерами выборки."
  },
  {
    "question": "Какую модель вы бы выбрали для создания системы рекомендаций на основе истории взаимодействий пользователя?",
    "options": [
      "Matrix Factorization",
      "BERT",
      "CNN",
      "ResNet"
    ],
    "explanation": "Для создания системы рекомендаций обычно используют методы матричной факторизации, которые анализируют взаимодействие пользователей с продуктами, или гибридные модели."
  },
  {
    "question": "Какую модель следует использовать для классификации текста, например, для анализа настроений в социальных сетях?",
    "options": [
      "BERT",
      "LSTM",
      "XGBoost",
      "ResNet"
    ],
    "explanation": "Для классификации текста, например, для анализа настроений, используется BERT, так как эта модель оптимизирована для обработки текстовых данных и захвата контекста."
  },
  {
    "question": "Какую модель вы бы использовали для восстановления изображений (например, уменьшение шума)?",
    "options": [
      "Autoencoder",
      "GAN",
      "LSTM",
      "SVM"
    ],
    "explanation": "Autoencoder — это модель, которая используется для восстановления изображений, таких как удаление шума или восстановление утраченных деталей."
  },
  {
    "question": "Какую модель выбрать для классификации звуковых данных (например, распознавание речи)?",
    "options": [
      "CNN",
      "LSTM",
      "ResNet",
      "BERT"
    ],
    "explanation": "Для классификации звуковых данных часто используют LSTM или гибридные модели с CNN, так как они хорошо обрабатывают временные и последовательные данные."
  },
  {
    "question": "Какую модель следует использовать для генерации текста (например, для создания искусственного текста)?",
    "options": [
      "GPT-3",
      "BERT",
      "SVM",
      "ResNet"
    ],
    "explanation": "GPT-3 (Generative Pre-trained Transformer) идеально подходит для генерации текста, так как эта модель обучена на огромном количестве текстов и может генерировать осмысленные фрагменты текста."
  },
  {
    "question": "Какую модель использовать для прогнозирования финансовых показателей на основе исторических данных?",
    "options": [
      "LSTM",
      "SVM",
      "BERT",
      "ResNet"
    ],
    "explanation": "LSTM хорошо справляется с задачами прогнозирования временных рядов, таких как предсказание финансовых показателей, благодаря способности учитывать временные зависимости."
  },
  {
    "question": "Какую модель выбрать для улучшения точности классификации изображений, используя ансамбли моделей?",
    "options": [
      "XGBoost",
      "CNN",
      "ResNet",
      "SVM"
    ],
    "explanation": "XGBoost и другие методы ансамблей, такие как случайный лес, могут быть использованы для улучшения точности классификации, комбинируя несколько моделей для получения более точных результатов."
  },
  {
    "question": "Какая модель наиболее подходящая для работы с изображениями, когда необходимо извлечь сложные признаки?",
    "options": [
      "ResNet",
      "SVM",
      "LSTM",
      "BERT"
    ],
    "explanation": "ResNet (Residual Network) используется для извлечения сложных признаков из изображений, благодаря своим остаточным связям, которые помогают обучать очень глубокие нейронные сети."
  },
  {
    "question": "Какая модель лучше всего подходит для обработки больших объемов данных, состоящих из различных типов информации (например, текст, изображения и таблицы)?",
    "options": [
      "Transformer",
      "GAN",
      "LSTM",
      "BERT"
    ],
    "explanation": "Transformer, с его гибкой архитектурой, может обрабатывать различные типы данных (например, текст, изображения и таблицы) благодаря механизму внимания."
  },
  {
    "question": "Какую модель следует использовать для предсказания вероятности события на основе табличных данных?",
    "options": [
      "XGBoost",
      "BERT",
      "CNN",
      "LSTM"
    ],
    "explanation": "XGBoost — это алгоритм градиентного бустинга, который является эффективным для работы с табличными данными, где требуется предсказать вероятность события."
  },
  {
    "question": "Какую модель вы бы использовали для создания искусственного изображения на основе текстового описания?",
    "options": [
      "DALL-E",
      "BERT",
      "ResNet",
      "LSTM"
    ],
    "explanation": "DALL-E — это модель, которая способна генерировать изображения на основе текстовых описаний, используя архитектуру Transformer."
  },
  {
    "question": "Какую модель вы бы использовали для анализа и классификации генетических данных?",
    "options": [
      "Random Forest",
      "LSTM",
      "ResNet",
      "SVM"
    ],
    "explanation": "Для анализа генетических данных могут быть использованы методы машинного обучения, такие как случайные леса (Random Forest), которые хорошо подходят для работы с большим количеством признаков."
  },
  {
    "question": "Какую модель лучше всего использовать для сегментации речи на звуки или слова?",
    "options": [
      "RNN",
      "LSTM",
      "CNN",
      "XGBoost"
    ],
    "explanation": "RNN и LSTM эффективно работают для сегментации речи на звуки или слова, так как они могут учитывать временные зависимости в аудиопоследовательностях."
  },
  {
    "question": "Какую модель использовать для поиска схожих документов в большом наборе текста (например, для поиска похожих статей)?",
    "options": [
      "Siamese Network",
      "ResNet",
      "LSTM",
      "XGBoost"
    ],
    "explanation": "Для задачи поиска схожих документов лучше использовать Siamese Network, которая обучается на парных примерах для нахождения схожести между текстами."
  },
  {
    "question": "Какую модель использовать для определения аномалий в данных (например, для обнаружения мошенничества)?",
    "options": [
      "Autoencoder",
      "ResNet",
      "BERT",
      "LSTM"
    ],
    "explanation": "Autoencoder может быть использован для обнаружения аномалий в данных, так как он учится восстанавливать данные и может выявить необычные или аномальные паттерны."
  },
  {
    "question": "Какой метод анализа данных используется для выявления скрытых зависимостей между переменными в больших наборах данных?",
    "options": [
      "Корреляционный анализ",
      "Регрессия",
      "Кластеризация",
      "Факторный анализ"
    ],
    "explanation": "Корреляционный анализ используется для выявления зависимости между переменными, измеряя, насколько сильно они взаимосвязаны."
  },
  {
    "question": "Какой метод применяется для уменьшения размерности данных при сохранении наиболее важной информации?",
    "options": [
      "Метод главных компонент (PCA)",
      "Логистическая регрессия",
      "Иерархическая кластеризация",
      "Картирование многомерных шкал"
    ],
    "explanation": "Метод главных компонент (PCA) помогает уменьшить размерность данных, сохраняя наиболее значимую информацию, что упрощает анализ и визуализацию."
  },
  {
    "question": "Какой из методов является основным для определения категории объекта в задаче классификации?",
    "options": [
      "Классификация",
      "Регрессия",
      "Кластеризация",
      "Оценка"
    ],
    "explanation": "Задача классификации требует использования алгоритмов, которые определяют, к какой категории принадлежит объект, например, использование логистической регрессии или деревьев решений."
  },
  {
    "question": "Какой алгоритм анализа данных подходит для определения групп схожих объектов в наборе данных?",
    "options": [
      "K-means кластеризация",
      "Логистическая регрессия",
      "Линейная регрессия",
      "Корреляционный анализ"
    ],
    "explanation": "K-means кластеризация используется для группировки данных на основе схожести, что позволяет выделить кластеры, в которых объекты похожи."
  },
  {
    "question": "Что из ниже перечисленного является основной целью нормализации данных?",
    "options": [
      "Привести все признаки к единому масштабу",
      "Уменьшить количество признаков",
      "Ускорить обучение модели",
      "Снизить зависимость от масштабов разных признаков"
    ],
    "explanation": "Нормализация данных позволяет привести все признаки к единому масштабу, что важно для корректной работы многих алгоритмов, таких как градиентный спуск."
  },
  {
    "question": "Какой из методов оценки модели используется для проверки точности предсказаний на обучающей выборке?",
    "options": [
      "Кросс-валидация",
      "Решение деревьев",
      "Скользящий контроль",
      "Оценка точности"
    ],
    "explanation": "Кросс-валидация используется для оценки точности модели, разделяя данные на несколько частей и обучая модель на различных подмножествах."
  },
  {
    "question": "Какую задачу решает метод регуляризации в моделях машинного обучения?",
    "options": [
      "Предотвращение переобучения",
      "Ускорение вычислений",
      "Уменьшение точности модели",
      "Оптимизация гиперпараметров"
    ],
    "explanation": "Регуляризация помогает предотвратить переобучение, добавляя штрафы за слишком сложные модели, чтобы улучшить их обобщающую способность."
  },
  {
    "question": "Какой из методов может быть использован для определения важности отдельных признаков в задаче классификации?",
    "options": [
      "Деревья решений",
      "Кластеризация",
      "Линейная регрессия",
      "Метод ближайших соседей"
    ],
    "explanation": "Деревья решений помогают определить важность признаков, поскольку на каждом шаге дерева выбирается наиболее важный признак для разбиения."
  },
  {
    "question": "Что такое метод случайного леса (Random Forest)?",
    "options": [
      "Алгоритм ансамблевого обучения",
      "Алгоритм для классификации текста",
      "Метод оценки значимости признаков",
      "Метод для анализа временных рядов"
    ],
    "explanation": "Случайный лес — это метод ансамблевого обучения, который использует несколько деревьев решений для повышения точности модели и уменьшения переобучения."
  },
  {
    "question": "Какую роль играет процедура отбора признаков в машинном обучении?",
    "options": [
      "Повышение точности модели за счет удаления нерелевантных признаков",
      "Уменьшение количества объектов данных",
      "Ускорение обучения модели за счет увеличения числа признаков",
      "Обучение модели с использованием только числовых данных"
    ],
    "explanation": "Отбор признаков помогает улучшить производительность модели, убирая признаки, которые не дают полезной информации для предсказания."
  },
  {
    "question": "Какая из этих метрик используется для оценки качества модели регрессии?",
    "options": [
      "Средняя квадратичная ошибка (MSE)",
      "Точность",
      "F1-меры",
      "Ранговая корреляция"
    ],
    "explanation": "Средняя квадратичная ошибка (MSE) — это метрика, которая используется для оценки точности предсказаний в задачах регрессии."
  },
  {
    "question": "Какой метод используется для проверки статистической значимости различий между группами?",
    "options": [
      "Тест Манна-Уитни",
      "Регрессия",
      "Кластеризация",
      "Решающие деревья"
    ],
    "explanation": "Тест Манна-Уитни используется для оценки статистической значимости различий между двумя независимыми группами."
  },
  {
    "question": "Какой метод классификации используется для решения задачи с нелинейными границами между классами?",
    "options": [
      "SVM с ядром",
      "Логистическая регрессия",
      "K-ближайших соседей",
      "Naive Bayes"
    ],
    "explanation": "SVM с ядром позволяет эффективно классифицировать данные с нелинейными границами между классами, используя различные виды ядер."
  },
  {
    "question": "Что такое переобучение (overfitting) модели?",
    "options": [
      "Модель слишком хорошо подгоняет данные, теряя способность обобщать на новые данные",
      "Модель имеет низкую точность на обучающих данных",
      "Модель слишком проста и не может захватить сложные зависимости",
      "Модель слишком долго обучалась"
    ],
    "explanation": "Переобучение происходит, когда модель слишком хорошо подстраивается под тренировочные данные, но не может обобщать на новые, неизвестные данные."
  },
  {
    "question": "Какой метод используется для обнаружения выбросов в наборе данных?",
    "options": [
      "Метод IQR (межквартильный размах)",
      "Регрессия",
      "Оценка плотности",
      "Кластеризация"
    ],
    "explanation": "Метод IQR используется для определения выбросов путем вычисления разницы между первым и третьим квартилем, и все значения за пределами этого диапазона считаются выбросами."
  },
  {
    "question": "Какую задачу решает метод линейной регрессии?",
    "options": [
      "Предсказание числового значения на основе линейной зависимости",
      "Классификация объектов на категории",
      "Кластеризация данных",
      "Выявление аномалий"
    ],
    "explanation": "Линейная регрессия используется для предсказания числовых значений на основе линейной зависимости между входными переменными."
  },
  {
    "question": "Какой метод анализа данных используется для выявления структуры и группы в данных без заранее заданных меток?",
    "options": [
      "Кластеризация",
      "Классификация",
      "Регрессия",
      "Нормализация"
    ],
    "explanation": "Кластеризация — это метод, который используется для группировки данных в кластеры, основываясь на их схожести, без заранее заданных меток."
  },
  {
    "question": "Какую роль в анализе данных играет визуализация данных?",
    "options": [
      "Помогает выявить закономерности и аномалии в данных",
      "Уменьшает размер данных",
      "Ускоряет процесс обучения моделей",
      "Используется только для презентаций"
    ],
    "explanation": "Визуализация данных помогает лучше понять данные, выявить скрытые закономерности и аномалии, а также облегчить интерпретацию результатов."
  },
  {
    "question": "Какая из этих техник используется для балансировки классов в задачах классификации?",
    "options": [
      "Oversampling",
      "Регрессия",
      "Кластеризация",
      "Метод главных компонент"
    ],
    "explanation": "Oversampling — это техника, которая используется для увеличения числа объектов меньшинства в несбалансированных классах для улучшения точности классификации."
  },
  {
    "question": "Что происходит, когда вы используете ключевое слово `global` в функции Python? Как это влияет на область видимости переменных?",
    "options": [
      "Переменная становится доступной во всей программе",
      "Переменная сохраняет значение только в функции",
      "Переменная доступна только в блоке, где она определена",
      "Переменная становится доступной в глобальной области видимости"
    ],
    "explanation": "Использование ключевого слова `global` в функции позволяет изменять глобальную переменную, и эта переменная становится доступной во всей программе, включая все функции."
  },
  {
    "question": "Какой результат будет получен при попытке вызвать функцию с аргументом, который не соответствует заявленному типу, если включен `type hints`?",
    "options": [
      "Python выбросит ошибку типа во время выполнения",
      "Python проигнорирует несоответствие типа, так как это только подсказки",
      "Python выбросит ошибку синтаксиса",
      "Python автоматически преобразует типы для совместимости"
    ],
    "explanation": "Type hints в Python — это подсказки для статического анализа кода, и они не приводят к выбросу ошибки во время выполнения. Python не ограничивает типы, но с помощью этих подсказок можно обнаружить несоответствия с помощью инструментов анализа кода, таких как `mypy`."
  },
  {
    "question": "Как работает метод `__getitem__` в Python, и чем он отличается от стандартного обращения к элементам через индексы?",
    "options": [
      "Он позволяет переопределить поведение индексации для объектов",
      "Он используется только в контексте словарей и списков",
      "Он автоматически вызывает `__setitem__` при присваивании значения",
      "Он не может быть использован с пользовательскими классами"
    ],
    "explanation": "Метод `__getitem__` позволяет переопределить поведение индексации для объектов. Это даёт возможность создавать классы, которые могут использовать операцию индексации с объектами, например, как с коллекциями."
  },
  {
    "question": "Какая из следующих ситуаций может привести к утечке памяти в Python, несмотря на автоматическую сборку мусора?",
    "options": [
      "Циклические ссылки между объектами, которые не могут быть удалены сборщиком мусора",
      "Использование слишком большого количества переменных в локальной области видимости",
      "Переход от Python 2 к Python 3",
      "Создание объектов внутри функций без использования `del`"
    ],
    "explanation": "Циклические ссылки могут привести к утечке памяти, если объекты в цикле ссылаются друг на друга, но сборщик мусора не может освободить память из-за этих циклических ссылок. Это проблема, которая решается в Python через модуль `gc`."
  },
  {
    "question": "Что происходит при использовании метода `super()` в Python, и почему его часто применяют в контексте многократного наследования?",
    "options": [
      "Он позволяет вызвать методы родительского класса, обходя цепочку наследования",
      "Он всегда вызывает метод самого первого родительского класса",
      "Он используется для получения доступа к приватным аттрибутам родительского класса",
      "Он блокирует вызов метода в родительском классе"
    ],
    "explanation": "`super()` используется для вызова метода родительского класса в цепочке наследования, что особенно полезно в многократном наследовании, где порядок вызова методов может быть сложным."
  },
  {
    "question": "Каким образом можно оптимизировать использование памяти в Python при работе с большими наборами данных?",
    "options": [
      "Использовать генераторы вместо списков",
      "Применять многозадачность для параллельной обработки данных",
      "Использовать типы данных с фиксированным размером",
      "Все вышеперечисленное"
    ],
    "explanation": "Использование генераторов вместо списков помогает сэкономить память, так как генераторы создают элементы по мере необходимости, а не загружают все элементы в память сразу. Также использование многозадачности и эффективных типов данных помогает в оптимизации работы с большими данными."
  },
  {
    "question": "Какой из этих механизмов Python использует для синхронизации доступа к общим данным при многозадачности?",
    "options": [
      "Мьютексы и блокировки",
      "Декораторы",
      "Генераторы",
      "Ключевое слово `yield`"
    ],
    "explanation": "Для синхронизации доступа к общим данным при многозадачности в Python используются мьютексы и блокировки, которые обеспечивают безопасность при параллельном доступе к данным."
  },
  {
    "question": "Какова основная цель функции `lambda` в Python, и в чем её отличие от обычной функции?",
    "options": [
      "Создание анонимных функций для краткости",
      "Использование только с коллекциями данных",
      "Обеспечение лучшей читаемости кода",
      "Ускорение работы программы"
    ],
    "explanation": "Функция `lambda` используется для создания кратких анонимных функций, которые могут быть использованы непосредственно в местах вызова, например, в качестве аргумента для других функций."
  },
  {
    "question": "Что произойдет, если попытаться изменить кортеж (tuple) в Python?",
    "options": [
      "Произойдет ошибка TypeError, так как кортежи неизменяемы",
      "Кортеж будет преобразован в список",
      "Кортеж будет изменен, так как он может быть изменен",
      "Ничего не произойдет, кортеж будет изменен без ошибок"
    ],
    "explanation": "Кортежи в Python являются неизменяемыми, и попытка их изменения приведет к ошибке `TypeError`."
  },
  {
    "question": "Какой механизм Python используется для работы с файлами в асинхронном режиме?",
    "options": [
      "Модуль `aiofiles`",
      "Модуль `os`",
      "Модуль `subprocess`",
      "Модуль `fileinput`"
    ],
    "explanation": "Для асинхронной работы с файлами в Python используется модуль `aiofiles`, который предоставляет асинхронные версии операций с файлами."
  },
  {
    "question": "Что такое GIL (Global Interpreter Lock) в Python, и как он влияет на многозадачность?",
    "options": [
      "GIL — это механизм, который ограничивает выполнение нескольких потоков в одном процессе, что может уменьшить эффективность многозадачности",
      "GIL — это механизм для улучшения работы с базами данных",
      "GIL — это библиотека для повышения производительности кода",
      "GIL — это функция, которая позволяет эффективно работать с многозадачностью"
    ],
    "explanation": "GIL (Global Interpreter Lock) ограничивает выполнение нескольких потоков в одном процессе Python, что влияет на производительность многозадачности, особенно в многопроцессорных системах."
  },
  {
    "question": "Что происходит при использовании декоратора `@staticmethod` в Python, и как он отличается от обычного метода класса?",
    "options": [
      "Метод с `@staticmethod` не имеет доступа к экземпляру класса и его аттрибутам",
      "Метод с `@staticmethod` не может быть вызван без экземпляра класса",
      "Метод с `@staticmethod` всегда является приватным",
      "Метод с `@staticmethod` должен быть вызван только через класс"
    ],
    "explanation": "Декоратор `@staticmethod` обозначает метод, который не имеет доступа к экземпляру класса или его аттрибутам, и может быть вызван напрямую через класс, не требуя экземпляра."
  },
  {
    "question": "Что происходит, если вы используете ключевое слово `del` для удаления переменной в Python?",
    "options": [
      "Переменная будет удалена из памяти, и доступ к ней вызовет ошибку",
      "Переменная будет переименована в `None`",
      "Переменная станет доступна для использования в других частях программы",
      "Переменная будет удалена только в текущей функции, но доступна в других областях видимости"
    ],
    "explanation": "Ключевое слово `del` удаляет переменную из памяти, и попытка обращения к ней после удаления вызовет ошибку `NameError`."
  },
  {
    "question": "Каким образом Python решает проблему повторяющихся вычислений при использовании кэширования функций с `functools.lru_cache`?",
    "options": [
      "Кэшируются результаты функции для уникальных аргументов, чтобы избежать повторных вычислений",
      "Кэшируются только аргументы функции, чтобы сэкономить память",
      "Каждый вызов функции выполняется заново, но сохраняется результат в глобальной области видимости",
      "Кэширование происходит автоматически без указания количества элементов в кеше"
    ],
    "explanation": "`functools.lru_cache` кэширует результаты функции для уникальных аргументов, что позволяет избежать повторных вычислений для тех же входных данных, что повышает производительность, особенно для дорогих функций."
  },
  {
    "question": "Как работают генераторы в Python и чем они отличаются от обычных итераторов?",
    "options": [
      "Генераторы используют `yield` для создания итераторов, которые генерируют элементы по мере необходимости, в отличие от обычных итераторов, которые загружают все элементы в память сразу",
      "Генераторы создают список, а итераторы возвращают значения по одному",
      "Генераторы всегда работают быстрее, чем обычные итераторы",
      "Итераторы всегда используют `yield`"
    ],
    "explanation": "Генераторы используют `yield` для создания итераторов, которые генерируют элементы по мере необходимости. Это позволяет экономить память, поскольку элементы не загружаются в память целиком."
  },
  {
    "question": "Что происходит при изменении атрибутов объекта, если объект является экземпляром класса с метаклассом?",
    "options": [
      "Метакласс может изменить поведение атрибутов объекта, перехватывая их доступ и модификацию",
      "Атрибуты объекта не могут быть изменены, если класс имеет метакласс",
      "Метакласс всегда блокирует изменение атрибутов объекта",
      "Метакласс применяет атрибуты ко всем объектам одного класса"
    ],
    "explanation": "Метаклассы в Python могут перехватывать создание классов и управление их атрибутами. Они могут изменять поведение атрибутов объекта, перехватывая доступ к ним, что даёт больше гибкости в управлении классами."
  },
  {
    "question": "Что произойдет, если при работе с многозадачностью в Python использовать модули `threading` и `multiprocessing` одновременно?",
    "options": [
      "Они будут работать в отдельных пространствах памяти, и это может вызвать синхронизационные проблемы",
      "Они будут работать без проблем, так как оба модуля предназначены для многозадачности",
      "Они приведут к блокировке программы, поскольку оба модуля используют один и тот же процесс",
      "Модуль `multiprocessing` автоматически решит все проблемы многозадачности, игнорируя `threading`"
    ],
    "explanation": "Модуль `threading` работает с потоками в одном процессе, а `multiprocessing` запускает отдельные процессы. Использование их вместе требует внимательности, чтобы избежать проблем с синхронизацией и блокировками."
  },
  {
    "question": "Как Python управляет памятью при создании новых объектов, и как работает сборщик мусора?",
    "options": [
      "Python использует ссылочную подсчетную систему для управления памятью, и сборщик мусора удаляет объекты, на которые больше нет ссылок",
      "Python использует систему автоматического освобождения памяти, но сборщик мусора работает только с большими объектами",
      "Python всегда освобождает память автоматически, без необходимости в сборщике мусора",
      "Сборщик мусора работает только в случае переполнения памяти"
    ],
    "explanation": "Python использует ссылочную подсчетную систему для управления памятью, а сборщик мусора удаляет объекты, на которые больше нет ссылок. Это помогает эффективно управлять памятью и избегать утечек."
  },
  {
    "question": "Какое преимущество у использования функции `map()` в Python по сравнению с циклом `for`?",
    "options": [
      "Функция `map()` позволяет параллельно обрабатывать элементы, улучшая производительность",
      "Функция `map()` возвращает новый список, не изменяя оригинальный",
      "Функция `map()` всегда работает быстрее, чем `for`-цикл",
      "Функция `map()` является более читаемой, чем использование циклов"
    ],
    "explanation": "Функция `map()` применяется для обработки элементов последовательности с помощью функции, возвращая итератор. Это может быть более эффективным, чем использование цикла, и позволяет избежать изменения исходных данных."
  },
  {
    "question": "Что происходит при сравнении двух объектов с помощью оператора `is` в Python?",
    "options": [
      "Оператор `is` проверяет, ссылаются ли два объекта на один и тот же участок памяти",
      "Оператор `is` проверяет, равны ли два объекта по значению",
      "Оператор `is` используется только для проверки идентичности классов",
      "Оператор `is` всегда возвращает `True` для всех объектов того же типа"
    ],
    "explanation": "Оператор `is` в Python проверяет, ссылаются ли два объекта на один и тот же участок памяти, то есть, являются ли они идентичными, а не равными по значению."
  },
  {
    "question": "Какая разница между `deepcopy` и обычным `copy` в Python?",
    "options": [
      "`deepcopy` создает полную копию объекта, включая все вложенные объекты, тогда как `copy` создает поверхностную копию",
      "`deepcopy` делает объект более быстрым для изменений, чем обычный `copy`",
      "`deepcopy` копирует только ссылки на вложенные объекты",
      "`deepcopy` используется только для коллекций данных, таких как списки и множества"
    ],
    "explanation": "`deepcopy` создает полную копию объекта, включая все вложенные объекты, в отличие от `copy`, который создает только поверхностную копию и копирует только ссылки на вложенные объекты."
  }
]
